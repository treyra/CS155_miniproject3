{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Indecision_Trees_Notebook_MiniProject_3",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/treyra/CS155_miniproject3/blob/main/Indecision_Trees_Notebook_MiniProject_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqIVzr9fXRz3"
      },
      "source": [
        "#Data Pre-processing\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwUm54mhYliJ"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CBwIp4TQYeT_",
        "outputId": "b9317ef4-23ff-4069-ca89-cf8158a775bc"
      },
      "source": [
        "# read in the data\n",
        "# Import Data\n",
        "data = np.genfromtxt('https://raw.githubusercontent.com/lakigigar/Caltech-CS155-2021/main/projects/project3/data/shakespeare.txt',delimiter='\\t',dtype=None,encoding='ISO-8859-1')\n",
        "data[-15]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'154'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWjzTm1TY-Us"
      },
      "source": [
        "# make all words lower case\n",
        "for i in range(len(data)):\n",
        "  data[i]=data[i].lower()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTZh0lAeajPB"
      },
      "source": [
        "# remove space at beginning of line\n",
        "for i in range(len(data)):\n",
        "  while data[i][0] == ' ':\n",
        "    line = list(data[i])\n",
        "    data[i] = \"\".join(line[1:len(line)])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faG6yVLGbrUK"
      },
      "source": [
        "# remove \\n\n",
        "for i in range(len(data)):\n",
        "        data[i] = data[i].replace('\\n', '')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFb9hQSUbz_d"
      },
      "source": [
        "# remove punctuation\n",
        "to_remove = ['.', ',', ';', ':', '?', '!', '-', \"'\"]\n",
        "for k in range(len(to_remove)):\n",
        "  for i in range(len(data)):\n",
        "    data[i] = ''.join([j for j in data[i] if j not in to_remove])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WOHcW20X2sf"
      },
      "source": [
        "# remove empty lines\n",
        "# find indices to remove\n",
        "remove_idx = []\n",
        "for i in range(len(data)):\n",
        "  if data[i] == '\\n':\n",
        "    remove_idx.append(i)\n",
        "  if data[i] == '':\n",
        "    remove_idx.append(i)\n",
        "# remove\n",
        "data_clean = []\n",
        "for k in range(len(data)):\n",
        "  if k not in remove_idx:\n",
        "    data_clean.append(data[k])\n",
        "data = data_clean"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijE-a5WWdmi9",
        "outputId": "7867bea3-6c04-4c26-b7d7-99dd06c34f7e"
      },
      "source": [
        "# remove sonnets which are too long or too short\n",
        "# always 14 lines long\n",
        "# check how long each sonnet is - should be 14!\n",
        "digit_idxs = []\n",
        "for i in range(len(data)):\n",
        "  if data[i].isdigit():\n",
        "    digit_idxs.append(i)\n",
        "#print(digit_idxs)\n",
        "# get difference\n",
        "length = np.diff(np.array(digit_idxs))\n",
        "#print(length)\n",
        "# remove the sonnet with too many or too few lines\n",
        "remove_nbrs = dict()\n",
        "for i in range(len(length)):\n",
        "  if length[i]!=15:\n",
        "    remove_nbrs.update({data[digit_idxs[i]]:length[i]})\n",
        "# remove the sonnets with the numbers in remove_numbers\n",
        "remove_idx = []\n",
        "for i in range(len(data)):\n",
        "  if data[i] in remove_nbrs:\n",
        "    print(data[i])\n",
        "    for k in range(0,remove_nbrs[data[i]]):\n",
        "      remove_idx.append(i+k)\n",
        "# remove\n",
        "data_clean = []\n",
        "for k in range(len(data)):\n",
        "  if k not in remove_idx:\n",
        "    data_clean.append(data[k])\n",
        "data = data_clean"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99\n",
            "126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfeWb8KGYI4C"
      },
      "source": [
        "# remove numbers\n",
        "for i in range(len(data)):\n",
        "  data[i] = ''.join([j for j in data[i] if not j.isdigit()])\n",
        "# remove created empty lines again\n",
        "# find indices to remove\n",
        "remove_idx = []\n",
        "for i in range(len(data)):\n",
        "  if data[i] == '\\n':\n",
        "    remove_idx.append(i)\n",
        "  if data[i] == '':\n",
        "    remove_idx.append(i)\n",
        "# remove\n",
        "data_clean = []\n",
        "for k in range(len(data)):\n",
        "  if k not in remove_idx:\n",
        "    data_clean.append(data[k])\n",
        "data = data_clean"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDdcig86YOrb"
      },
      "source": [
        "# this is the data per line\n",
        "data_by_line = data"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZhwdlDLfaTK"
      },
      "source": [
        "# get data per sonnet\n",
        "# split up in sonnets\n",
        "nr_sonnets = len(data)/14\n",
        "data_by_sonnet = [None] * int(nr_sonnets)\n",
        "i = 0\n",
        "for k in range(0, len(data), 14):\n",
        "  cString = ''\n",
        "  for idx in range(14):\n",
        "    #print(idx)\n",
        "    if idx != 0:\n",
        "      try:\n",
        "        cString = cString + ' ' + data[k + idx]\n",
        "      except:\n",
        "        import pdb; pdb.set_trace()\n",
        "    else: \n",
        "      cString = data[k]\n",
        "  data_by_sonnet[i] = cString\n",
        "  i+=1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9dxC62XZSzC"
      },
      "source": [
        "# make new file for data per line\n",
        "with open('/content/drive/My Drive/CS155_miniproject_3/data_line.txt', 'w') as f:\n",
        "  for item in data_by_line:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY0xUd3KbjXB"
      },
      "source": [
        "# make new file for data per sonnet\n",
        "with open('/content/drive/My Drive/CS155_miniproject_3/data_sonnet.txt', 'w') as f:\n",
        "  for item in data_by_sonnet:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ibninVYXaKH"
      },
      "source": [
        "We can also load the pre-processed data directly as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR0TkrchXYb9"
      },
      "source": [
        "# load the data - for now from drive until we have repo\r\n",
        "# open existing text file\r\n",
        "data_sonnet = np.genfromtxt('https://raw.githubusercontent.com/treyra/CS155_miniproject3/main/data/data_sonnet.txt',delimiter='\\t',dtype=None,encoding='ISO-8859-1')\r\n",
        "data_line = np.genfromtxt('https://raw.githubusercontent.com/treyra/CS155_miniproject3/main/data/data_line.txt',delimiter='\\t',dtype=None,encoding='ISO-8859-1')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYCseFowX1pv"
      },
      "source": [
        "#TO DO: Replace with HW 6 solutions\r\n",
        "\r\n",
        "class HiddenMarkovModel:\r\n",
        "    '''\r\n",
        "    Class implementation of Hidden Markov Models.\r\n",
        "    '''\r\n",
        "\r\n",
        "    def __init__(self, A, O):\r\n",
        "        '''\r\n",
        "        Initializes an HMM. Assumes the following:\r\n",
        "            - States and observations are integers starting from 0. \r\n",
        "            - There is a start state (see notes on A_start below). There\r\n",
        "              is no integer associated with the start state, only\r\n",
        "              probabilities in the vector A_start.\r\n",
        "            - There is no end state.\r\n",
        "        Arguments:\r\n",
        "            A:          Transition matrix with dimensions L x L.\r\n",
        "                        The (i, j)^th element is the probability of\r\n",
        "                        transitioning from state i to state j. Note that\r\n",
        "                        this does not include the starting probabilities.\r\n",
        "            O:          Observation matrix with dimensions L x D.\r\n",
        "                        The (i, j)^th element is the probability of\r\n",
        "                        emitting observation j given state i.\r\n",
        "        Parameters:\r\n",
        "            L:          Number of states.\r\n",
        "            \r\n",
        "            D:          Number of observations.\r\n",
        "            \r\n",
        "            A:          The transition matrix.\r\n",
        "            \r\n",
        "            O:          The observation matrix.\r\n",
        "            \r\n",
        "            A_start:    Starting transition probabilities. The i^th element\r\n",
        "                        is the probability of transitioning from the start\r\n",
        "                        state to state i. For simplicity, we assume that\r\n",
        "                        this distribution is uniform.\r\n",
        "        '''\r\n",
        "\r\n",
        "        self.L = len(A)\r\n",
        "        self.D = len(O[0])\r\n",
        "        self.A = A\r\n",
        "        self.O = O\r\n",
        "        self.A_start = [1. / self.L for _ in range(self.L)]\r\n",
        "\r\n",
        "\r\n",
        "    def viterbi(self, x):\r\n",
        "        '''\r\n",
        "        Uses the Viterbi algorithm to find the max probability state \r\n",
        "        sequence corresponding to a given input sequence.\r\n",
        "        Arguments:\r\n",
        "            x:          Input sequence in the form of a list of length M,\r\n",
        "                        consisting of integers ranging from 0 to D - 1.\r\n",
        "        Returns:\r\n",
        "            max_seq:    State sequence corresponding to x with the highest\r\n",
        "                        probability.\r\n",
        "        '''\r\n",
        "\r\n",
        "        M = len(x)      # Length of sequence.\r\n",
        "\r\n",
        "        # The (i, j)^th elements of probs and seqs are the max probability\r\n",
        "        # of the prefix of length i ending in state j and the prefix\r\n",
        "        # that gives this probability, respectively.\r\n",
        "        #\r\n",
        "        # For instance, probs[1][0] is the probability of the prefix of\r\n",
        "        # length 1 ending in state 0.\r\n",
        "        probs = [[0. for _ in range(self.L)] for _ in range(M + 1)]\r\n",
        "        seqs = [['' for _ in range(self.L)] for _ in range(M + 1)]\r\n",
        "\r\n",
        "        ###\r\n",
        "        A = self.A\r\n",
        "        O = self.O\r\n",
        "        A_start = self.A_start\r\n",
        "        A1 = np.array(A)\r\n",
        "        A1_start = np.array(A_start)\r\n",
        "        B1 = np.array(O)\r\n",
        "\r\n",
        "        prob = np.zeros((self.L,M))\r\n",
        "        seq = np.zeros((self.L,M))\r\n",
        "        \r\n",
        "        prob[:,0] = A1_start * B1[:,x[0]]\r\n",
        "        seq[:,0] = 0\r\n",
        "\r\n",
        "        # update probabilities and sequences \r\n",
        "        for i in range(1,M):\r\n",
        "          prob[:,i]=np.max(prob[:,i-1]*A1.T*B1[:,x[i]].reshape(-1,1),1)\r\n",
        "          seq[:,i]=np.argmax(prob[:,i-1]*A1.T,1)\r\n",
        "\r\n",
        "        x_o = np.empty(M,'B')\r\n",
        "        x_o[-1] = np.argmax(prob[:,M-1])\r\n",
        "        for i in reversed(range(1,M)):\r\n",
        "          x_o[i-1]=seq[x_o[i],i]\r\n",
        "\r\n",
        "        x_o2 = x_o.tolist()\r\n",
        "        max_seq = ''.join([str(item) for item in x_o2])\r\n",
        "        return max_seq\r\n",
        "        ###\r\n",
        "\r\n",
        "        # max_seq = ''\r\n",
        "        # return max_seq\r\n",
        "\r\n",
        "\r\n",
        "    def forward(self, x, normalize=False):\r\n",
        "        '''\r\n",
        "        Uses the forward algorithm to calculate the alpha probability\r\n",
        "        vectors corresponding to a given input sequence.\r\n",
        "        Arguments:\r\n",
        "            x:          Input sequence in the form of a list of length M,\r\n",
        "                        consisting of integers ranging from 0 to D - 1.\r\n",
        "            normalize:  Whether to normalize each set of alpha_j(i) vectors\r\n",
        "                        at each i. This is useful to avoid underflow in\r\n",
        "                        unsupervised learning.\r\n",
        "        Returns:\r\n",
        "            alphas:     Vector of alphas.\r\n",
        "                        The (i, j)^th element of alphas is alpha_j(i),\r\n",
        "                        i.e. the probability of observing prefix x^1:i\r\n",
        "                        and state y^i = j.\r\n",
        "                        e.g. alphas[1][0] corresponds to the probability\r\n",
        "                        of observing x^1:1, i.e. the first observation,\r\n",
        "                        given that y^1 = 0, i.e. the first state is 0.\r\n",
        "        '''\r\n",
        "\r\n",
        "        M = len(x)      # Length of sequence.\r\n",
        "        alphas = [[0. for _ in range(self.L)] for _ in range(M + 1)]\r\n",
        "\r\n",
        "        ###\r\n",
        "        L = self.L\r\n",
        "        D = self.D\r\n",
        "        A = self.A\r\n",
        "        O = self.O\r\n",
        "        A_start = self.A_start\r\n",
        "        A1 = np.array(A)\r\n",
        "        A1_start = np.array(A_start)\r\n",
        "        O1 = np.array(O)\r\n",
        "        x1 = np.array(x)\r\n",
        "\r\n",
        "        alphas = np.zeros((M,self.L))\r\n",
        "        alphas[0,:] = A1_start * O1[:,x1[0]]\r\n",
        "\r\n",
        "        for idx1 in range(1,x1.shape[0]):\r\n",
        "          for idx2 in range(A1.shape[0]):\r\n",
        "            alphas[idx1,idx2]=alphas[idx1-1].dot(A1[:,idx2])*O1[idx2,x1[idx1]]\r\n",
        "\r\n",
        "        if normalize:\r\n",
        "          for idx1 in range(len(alphas)):\r\n",
        "            if np.sum(np.abs(alphas[idx1,:])) != 0:\r\n",
        "              alphas[idx1,:] = alphas[idx1,:]/np.sum(np.abs(alphas[idx1,:]))\r\n",
        "        ###\r\n",
        "\r\n",
        "        return alphas\r\n",
        "\r\n",
        "\r\n",
        "    def backward(self, x, normalize=False):\r\n",
        "        '''\r\n",
        "        Uses the backward algorithm to calculate the beta probability\r\n",
        "        vectors corresponding to a given input sequence.\r\n",
        "        Arguments:\r\n",
        "            x:          Input sequence in the form of a list of length M,\r\n",
        "                        consisting of integers ranging from 0 to D - 1.\r\n",
        "            normalize:  Whether to normalize each set of alpha_j(i) vectors\r\n",
        "                        at each i. This is useful to avoid underflow in\r\n",
        "                        unsupervised learning.\r\n",
        "        Returns:\r\n",
        "            betas:      Vector of betas.\r\n",
        "                        The (i, j)^th element of betas is beta_j(i), i.e.\r\n",
        "                        the probability of observing prefix x^(i+1):M and\r\n",
        "                        state y^i = j.\r\n",
        "                        e.g. betas[M][0] corresponds to the probability\r\n",
        "                        of observing x^M+1:M, i.e. no observations,\r\n",
        "                        given that y^M = 0, i.e. the last state is 0.\r\n",
        "        '''\r\n",
        "\r\n",
        "        M = len(x)      # Length of sequence.\r\n",
        "        betas = [[0. for _ in range(self.L)] for _ in range(M + 1)]\r\n",
        "\r\n",
        "        ###\r\n",
        "        A = self.A\r\n",
        "        L = self.L\r\n",
        "        D = self.D\r\n",
        "        O = self.O\r\n",
        "        A1 = np.array(A)\r\n",
        "        O1 = np.array(O)\r\n",
        "        x1 = np.array(x)\r\n",
        "        betas = np.zeros((M+1,L))\r\n",
        "        betas[-1,:] = 1\r\n",
        "        # update betas\r\n",
        "        for idx1 in range(M-1,-1,-1):\r\n",
        "          for idx2 in range(L):\r\n",
        "            betas[idx1,idx2]= (betas[idx1+1,:]*O1[:,x1[idx1]]).dot(A1[idx2,:])\r\n",
        "\r\n",
        "        if normalize:\r\n",
        "          for idx1 in range(0,len(betas)):\r\n",
        "            if np.sum(np.abs(betas[idx1,:])) != 0:\r\n",
        "              betas[idx1,:] = betas[idx1,:]/np.sum(np.abs(betas[idx1,:]))\r\n",
        "        ###\r\n",
        "\r\n",
        "        return betas\r\n",
        "\r\n",
        "\r\n",
        "    def supervised_learning(self, X, Y):\r\n",
        "        '''\r\n",
        "        Trains the HMM using the Maximum Likelihood closed form solutions\r\n",
        "        for the transition and observation matrices on a labeled\r\n",
        "        datset (X, Y). Note that this method does not return anything, but\r\n",
        "        instead updates the attributes of the HMM object.\r\n",
        "        Arguments:\r\n",
        "            X:          A dataset consisting of input sequences in the form\r\n",
        "                        of lists of variable length, consisting of integers \r\n",
        "                        ranging from 0 to D - 1. In other words, a list of\r\n",
        "                        lists.\r\n",
        "            Y:          A dataset consisting of state sequences in the form\r\n",
        "                        of lists of variable length, consisting of integers \r\n",
        "                        ranging from 0 to L - 1. In other words, a list of\r\n",
        "                        lists.\r\n",
        "                        Note that the elements in X line up with those in Y.\r\n",
        "        '''\r\n",
        "\r\n",
        "        # Calculate each element of A using the M-step formulas.\r\n",
        "\r\n",
        "        ###\r\n",
        "        A1 = np.array(self.A)\r\n",
        "\r\n",
        "        for idx1 in range(len(A1)):\r\n",
        "          for idx2 in range(len(A1[0])):\r\n",
        "            sum_a = 0\r\n",
        "            sum_b = 0\r\n",
        "            N = len(Y)\r\n",
        "            for idx3 in range(0,N):\r\n",
        "              Mj = len(Y[idx3])\r\n",
        "              for idx4 in range(0,Mj-1):\r\n",
        "                p1 = (Y[idx3][idx4+1] == idx2)\r\n",
        "                p2 = (Y[idx3][idx4]== idx1)\r\n",
        "                if p1==1 and p2==1:\r\n",
        "                  sum_a+=1\r\n",
        "                p3 = (Y[idx3][idx4]==idx1)\r\n",
        "                if p3==1:\r\n",
        "                  sum_b+=1\r\n",
        "                if sum_b == 0:\r\n",
        "                  self.A[idx1][idx2] = 0\r\n",
        "                else:\r\n",
        "                  self.A[idx1][idx2] = sum_a/sum_b\r\n",
        "\r\n",
        "        # Calculate each element of O using the M-step formulas.\r\n",
        "        O1 = np.array(self.O)\r\n",
        "\r\n",
        "        for z in range(len(O1)):\r\n",
        "          for w in range(len(O1[0])):\r\n",
        "            sum_a = 0\r\n",
        "            sum_b = 0\r\n",
        "            N = len(Y)\r\n",
        "            for idx3 in range(0,N):\r\n",
        "              Mj = len(X[idx3])\r\n",
        "              for idx4 in range(0,Mj):\r\n",
        "                p1 = (X[idx3][idx4]==w)\r\n",
        "                p2 = (Y[idx3][idx4]==z)\r\n",
        "                if p1 ==1 & p2==1:\r\n",
        "                  sum_a+=1\r\n",
        "                p3 = (Y[idx3][idx4]==z)\r\n",
        "                if p3 == 1:\r\n",
        "                  sum_b+=1\r\n",
        "                if sum_b == 0:\r\n",
        "                  self.O[z][w] = 0\r\n",
        "                else:\r\n",
        "                  self.O[z][w] = sum_a/sum_b\r\n",
        "              \r\n",
        "        ###\r\n",
        "\r\n",
        "        pass\r\n",
        "\r\n",
        "\r\n",
        "    def unsupervised_learning(self, X, N_iters):\r\n",
        "        '''\r\n",
        "        Trains the HMM using the Baum-Welch algorithm on an unlabeled\r\n",
        "        datset X. Note that this method does not return anything, but\r\n",
        "        instead updates the attributes of the HMM object.\r\n",
        "        Arguments:\r\n",
        "            X:          A dataset consisting of input sequences in the form\r\n",
        "                        of lists of length M, consisting of integers ranging\r\n",
        "                        from 0 to D - 1. In other words, a list of lists.\r\n",
        "            N_iters:    The number of iterations to train on.\r\n",
        "        '''\r\n",
        "\r\n",
        "        ###\r\n",
        "        for _ in range(N_iters):\r\n",
        "          L = self.L\r\n",
        "          D = self.D\r\n",
        "          Atop = np.zeros((L, L))\r\n",
        "          Abot = np.zeros((L, L))\r\n",
        "          Otop = np.zeros((L, D))\r\n",
        "          Obot = np.zeros((L, D))\r\n",
        "           \r\n",
        "          # loop\r\n",
        "          for idx1 in range(len(X)): \r\n",
        "            alphas = self.forward(X[idx1], True)\r\n",
        "            betas = self.backward(X[idx1], True)\r\n",
        "            P1 = np.zeros((len(alphas), len(alphas[0])))\r\n",
        "            # get first marginal\r\n",
        "            for b in range(0, len(alphas) ):\r\n",
        "              for c in range(L):\r\n",
        "                sum1 = 0\r\n",
        "                sum2 = 0\r\n",
        "                sum1 = alphas[b][:].dot(betas[b+1][:])\r\n",
        "                if sum1 != 0:\r\n",
        "                  P1[b][c] = alphas[b][c]*betas[b+1][c]/sum1\r\n",
        "            # get second marginal\r\n",
        "            L = self.L\r\n",
        "            P2 = np.zeros((len(X[idx1]), L, L))\r\n",
        "            A1 = np.array(self.A)\r\n",
        "            O1 = np.array(self.O)\r\n",
        "            for d in range(1, len(X[idx1])):\r\n",
        "              for e in range(L):              \r\n",
        "                for f in range(L): \r\n",
        "                  sum2 = 0\r\n",
        "                  sum3 = 0\r\n",
        "                  sum4 = 0\r\n",
        "                  sum4 = sum((np.array(alphas[d - 1][0:L]).dot((A1[0:L, 0:L])))*(O1[0:L, X[idx1][d]]*betas[d + 1][0:L]))\r\n",
        "                  if sum4 != 0:\r\n",
        "                    P2[d, e, f] = alphas[d - 1][e]*self.A[e][f]*self.O[f][X[idx1][d]]*betas[d + 1][f]/sum4\r\n",
        "            for g in range(L):              \r\n",
        "              for h in range(L):  \r\n",
        "                for i in range(0, len(X[idx1])-1):\r\n",
        "                  Abot[g][h] += P1[i][g]\r\n",
        "            for j in range(L):              \r\n",
        "              for k in range(L):  \r\n",
        "                for l in range(0, len(X[idx1])):\r\n",
        "                  Atop[j][k] += P2[l][j][k]\r\n",
        "            for m in range(D):  \r\n",
        "              for n in range(0, len(X[idx1])):\r\n",
        "                Otop[:, m] += P1[n, :]*(X[idx1][n] == m)\r\n",
        "            for o in range(D):\r\n",
        "              Obot[:, o] += np.sum(np.array(P1), axis = 0) \r\n",
        "                        \r\n",
        "          # compute new A and O\r\n",
        "          A = np.divide(Atop, Abot)\r\n",
        "          O = np.divide(Otop, Obot)\r\n",
        "          # save them\r\n",
        "          self.A = A\r\n",
        "          self.O = O\r\n",
        "        ###\r\n",
        "        pass\r\n",
        "\r\n",
        "\r\n",
        "    def generate_emission(self, M):\r\n",
        "        '''\r\n",
        "        Generates an emission of length M, assuming that the starting state\r\n",
        "        is chosen uniformly at random. \r\n",
        "        Arguments:\r\n",
        "            M:          Length of the emission to generate.\r\n",
        "        Returns:\r\n",
        "            emission:   The randomly generated emission as a list.\r\n",
        "            states:     The randomly generated states as a list.\r\n",
        "        '''\r\n",
        "\r\n",
        "        emission = []\r\n",
        "        states = []\r\n",
        "\r\n",
        "        ###\r\n",
        "        A = self.A\r\n",
        "        O = self.O\r\n",
        "        L = self.L\r\n",
        "        O1 = np.array(O)\r\n",
        "        A1 = np.array(A)\r\n",
        "        # set first state and emission\r\n",
        "        states.append(np.random.randint(0,L))\r\n",
        "        emission.append(np.random.choice(self.D,None,True,O1[states[0],:]))\r\n",
        "        # now go through\r\n",
        "        for idx in range(M-1):\r\n",
        "          states.append(np.random.choice(self.L,None,True,A1[states[idx],:]))\r\n",
        "          emission.append(np.random.choice(self.D,None,True,O1[states[idx+1],:]))\r\n",
        "        ###\r\n",
        "\r\n",
        "        return emission, states\r\n",
        "\r\n",
        "\r\n",
        "    def probability_alphas(self, x):\r\n",
        "        '''\r\n",
        "        Finds the maximum probability of a given input sequence using\r\n",
        "        the forward algorithm.\r\n",
        "        Arguments:\r\n",
        "            x:          Input sequence in the form of a list of length M,\r\n",
        "                        consisting of integers ranging from 0 to D - 1.\r\n",
        "        Returns:\r\n",
        "            prob:       Total probability that x can occur.\r\n",
        "        '''\r\n",
        "\r\n",
        "        # Calculate alpha vectors.\r\n",
        "        alphas = self.forward(x)\r\n",
        "\r\n",
        "        # alpha_j(M) gives the probability that the state sequence ends\r\n",
        "        # in j. Summing this value over all possible states j gives the\r\n",
        "        # total probability of x paired with any state sequence, i.e.\r\n",
        "        # the probability of x.\r\n",
        "        prob = sum(alphas[-1])\r\n",
        "        return prob\r\n",
        "\r\n",
        "\r\n",
        "    def probability_betas(self, x):\r\n",
        "        '''\r\n",
        "        Finds the maximum probability of a given input sequence using\r\n",
        "        the backward algorithm.\r\n",
        "        Arguments:\r\n",
        "            x:          Input sequence in the form of a list of length M,\r\n",
        "                        consisting of integers ranging from 0 to D - 1.\r\n",
        "        Returns:\r\n",
        "            prob:       Total probability that x can occur.\r\n",
        "        '''\r\n",
        "\r\n",
        "        betas = self.backward(x)\r\n",
        "\r\n",
        "        # beta_j(1) gives the probability that the state sequence starts\r\n",
        "        # with j. Summing this, multiplied by the starting transition\r\n",
        "        # probability and the observation probability, over all states\r\n",
        "        # gives the total probability of x paired with any state\r\n",
        "        # sequence, i.e. the probability of x.\r\n",
        "        prob = sum([betas[1][j] * self.A_start[j] * self.O[j][x[0]] \\\r\n",
        "                    for j in range(self.L)])\r\n",
        "\r\n",
        "        return prob\r\n",
        "\r\n",
        "\r\n",
        "def supervised_HMM(X, Y):\r\n",
        "    '''\r\n",
        "    Helper function to train a supervised HMM. The function determines the\r\n",
        "    number of unique states and observations in the given data, initializes\r\n",
        "    the transition and observation matrices, creates the HMM, and then runs\r\n",
        "    the training function for supervised learning.\r\n",
        "    Arguments:\r\n",
        "        X:          A dataset consisting of input sequences in the form\r\n",
        "                    of lists of variable length, consisting of integers \r\n",
        "                    ranging from 0 to D - 1. In other words, a list of lists.\r\n",
        "        Y:          A dataset consisting of state sequences in the form\r\n",
        "                    of lists of variable length, consisting of integers \r\n",
        "                    ranging from 0 to L - 1. In other words, a list of lists.\r\n",
        "                    Note that the elements in X line up with those in Y.\r\n",
        "    '''\r\n",
        "    # Make a set of observations.\r\n",
        "    observations = set()\r\n",
        "    for x in X:\r\n",
        "        observations |= set(x)\r\n",
        "\r\n",
        "    # Make a set of states.\r\n",
        "    states = set()\r\n",
        "    for y in Y:\r\n",
        "        states |= set(y)\r\n",
        "    \r\n",
        "    # Compute L and D.\r\n",
        "    L = len(states)\r\n",
        "    D = len(observations)\r\n",
        "\r\n",
        "    # Randomly initialize and normalize matrix A.\r\n",
        "    A = [[random.random() for i in range(L)] for j in range(L)]\r\n",
        "\r\n",
        "    for i in range(len(A)):\r\n",
        "        norm = sum(A[i])\r\n",
        "        for j in range(len(A[i])):\r\n",
        "            A[i][j] /= norm\r\n",
        "    \r\n",
        "    # Randomly initialize and normalize matrix O.\r\n",
        "    O = [[random.random() for i in range(D)] for j in range(L)]\r\n",
        "\r\n",
        "    for i in range(len(O)):\r\n",
        "        norm = sum(O[i])\r\n",
        "        for j in range(len(O[i])):\r\n",
        "            O[i][j] /= norm\r\n",
        "\r\n",
        "    # Train an HMM with labeled data.\r\n",
        "    HMM = HiddenMarkovModel(A, O)\r\n",
        "    HMM.supervised_learning(X, Y)\r\n",
        "\r\n",
        "    return HMM\r\n",
        "\r\n",
        "def unsupervised_HMM(X, n_states, N_iters,rng=np.random.RandomState(1)):\r\n",
        "    '''\r\n",
        "    Helper function to train an unsupervised HMM. The function determines the\r\n",
        "    number of unique observations in the given data, initializes\r\n",
        "    the transition and observation matrices, creates the HMM, and then runs\r\n",
        "    the training function for unsupervised learing.\r\n",
        "    Arguments:\r\n",
        "        X:          A dataset consisting of input sequences in the form\r\n",
        "                    of lists of variable length, consisting of integers \r\n",
        "                    ranging from 0 to D - 1. In other words, a list of lists.\r\n",
        "        n_states:   Number of hidden states to use in training.\r\n",
        "        \r\n",
        "        N_iters:    The number of iterations to train on.\r\n",
        "        rng:        The random number generator for reproducible result.\r\n",
        "                    Default to RandomState(1).\r\n",
        "    '''\r\n",
        "\r\n",
        "    # Make a set of observations.\r\n",
        "    observations = set()\r\n",
        "    for x in X:\r\n",
        "        observations |= set(x)\r\n",
        "    \r\n",
        "    # Compute L and D.\r\n",
        "    L = n_states\r\n",
        "    D = len(observations)\r\n",
        "\r\n",
        "    # Randomly initialize and normalize matrix A.\r\n",
        "    A = [[rng.random() for i in range(L)] for j in range(L)]\r\n",
        "\r\n",
        "    for i in range(len(A)):\r\n",
        "        norm = sum(A[i])\r\n",
        "        for j in range(len(A[i])):\r\n",
        "            A[i][j] /= norm\r\n",
        "    \r\n",
        "    # Randomly initialize and normalize matrix O.\r\n",
        "    O = [[rng.random() for i in range(D)] for j in range(L)]\r\n",
        "\r\n",
        "    for i in range(len(O)):\r\n",
        "        norm = sum(O[i])\r\n",
        "        for j in range(len(O[i])):\r\n",
        "            O[i][j] /= norm\r\n",
        "\r\n",
        "    # Train an HMM with unlabeled data.\r\n",
        "    HMM = HiddenMarkovModel(A, O)\r\n",
        "    HMM.unsupervised_learning(X, N_iters)\r\n",
        "\r\n",
        "    return HMM"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXMxhK5HYmzu"
      },
      "source": [
        "########################################\r\n",
        "# CS/CNS/EE 155 2018\r\n",
        "# Problem Set 6\r\n",
        "#\r\n",
        "# Author:       Andrew Kang\r\n",
        "# Description:  Set 6 HMM helper\r\n",
        "########################################\r\n",
        "\r\n",
        "import re\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from wordcloud import WordCloud\r\n",
        "from matplotlib import animation\r\n",
        "from matplotlib.animation import FuncAnimation\r\n",
        "\r\n",
        "\r\n",
        "####################\r\n",
        "# WORDCLOUD FUNCTIONS\r\n",
        "####################\r\n",
        "\r\n",
        "def mask():\r\n",
        "    # Parameters.\r\n",
        "    r = 128\r\n",
        "    d = 2 * r + 1\r\n",
        "\r\n",
        "    # Get points in a circle.\r\n",
        "    y, x = np.ogrid[-r:d-r, -r:d-r]\r\n",
        "    circle = (x**2 + y**2 <= r**2)\r\n",
        "\r\n",
        "    # Create mask.\r\n",
        "    mask = 255 * np.ones((d, d), dtype=np.uint8)\r\n",
        "    mask[circle] = 0\r\n",
        "\r\n",
        "    return mask\r\n",
        "\r\n",
        "def text_to_wordcloud(text, max_words=50, title='', show=True):\r\n",
        "    plt.close('all')\r\n",
        "\r\n",
        "    # Generate a wordcloud image.\r\n",
        "    wordcloud = WordCloud(random_state=0,\r\n",
        "                          max_words=max_words,\r\n",
        "                          background_color='white',\r\n",
        "                          mask=mask()).generate(text)\r\n",
        "\r\n",
        "    # Show the image.\r\n",
        "    if show:\r\n",
        "        plt.imshow(wordcloud, interpolation='bilinear')\r\n",
        "        plt.axis('off')\r\n",
        "        plt.title(title, fontsize=24)\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "    return wordcloud\r\n",
        "\r\n",
        "def states_to_wordclouds(hmm, obs_map, max_words=50, show=True):\r\n",
        "    # Initialize.\r\n",
        "    M = 100000\r\n",
        "    n_states = len(hmm.A)\r\n",
        "    obs_map_r = obs_map_reverser(obs_map)\r\n",
        "    wordclouds = []\r\n",
        "\r\n",
        "    # Generate a large emission.\r\n",
        "    emission, states = hmm.generate_emission(M)\r\n",
        "\r\n",
        "    # For each state, get a list of observations that have been emitted\r\n",
        "    # from that state.\r\n",
        "    obs_count = []\r\n",
        "    for i in range(n_states):\r\n",
        "        obs_lst = np.array(emission)[np.where(np.array(states) == i)[0]]\r\n",
        "        obs_count.append(obs_lst)\r\n",
        "\r\n",
        "    # For each state, convert it into a wordcloud.\r\n",
        "    for i in range(n_states):\r\n",
        "        obs_lst = obs_count[i]\r\n",
        "        sentence = [obs_map_r[j] for j in obs_lst]\r\n",
        "        sentence_str = ' '.join(sentence)\r\n",
        "\r\n",
        "        wordclouds.append(text_to_wordcloud(sentence_str, max_words=max_words, title='State %d' % i, show=show))\r\n",
        "\r\n",
        "    return wordclouds\r\n",
        "\r\n",
        "\r\n",
        "####################\r\n",
        "# HMM FUNCTIONS\r\n",
        "####################\r\n",
        "\r\n",
        "def parse_observations(text):\r\n",
        "    # Convert text to dataset.\r\n",
        "    lines = [line.split() for line in text.split('\\n') if line.split()]\r\n",
        "\r\n",
        "    obs_counter = 0\r\n",
        "    obs = []\r\n",
        "    obs_map = {}\r\n",
        "\r\n",
        "    for line in lines:\r\n",
        "        obs_elem = []\r\n",
        "        \r\n",
        "        for word in line:\r\n",
        "            word = re.sub(r'[^\\w]', '', word).lower()\r\n",
        "            if word not in obs_map:\r\n",
        "                # Add unique words to the observations map.\r\n",
        "                obs_map[word] = obs_counter\r\n",
        "                obs_counter += 1\r\n",
        "            \r\n",
        "            # Add the encoded word.\r\n",
        "            obs_elem.append(obs_map[word])\r\n",
        "        \r\n",
        "        # Add the encoded sequence.\r\n",
        "        obs.append(obs_elem)\r\n",
        "\r\n",
        "    return obs, obs_map\r\n",
        "\r\n",
        "def obs_map_reverser(obs_map):\r\n",
        "    obs_map_r = {}\r\n",
        "\r\n",
        "    for key in obs_map:\r\n",
        "        obs_map_r[obs_map[key]] = key\r\n",
        "\r\n",
        "    return obs_map_r\r\n",
        "\r\n",
        "def sample_sentence(hmm, obs_map, n_words=100):\r\n",
        "    # Get reverse map.\r\n",
        "    obs_map_r = obs_map_reverser(obs_map)\r\n",
        "\r\n",
        "    # Sample and convert sentence.\r\n",
        "    emission, states = hmm.generate_emission(n_words)\r\n",
        "    sentence = [obs_map_r[i] for i in emission]\r\n",
        "\r\n",
        "    return ' '.join(sentence).capitalize() + '...'\r\n",
        "\r\n",
        "\r\n",
        "####################\r\n",
        "# HMM VISUALIZATION FUNCTIONS\r\n",
        "####################\r\n",
        "\r\n",
        "def visualize_sparsities(hmm, O_max_cols=50, O_vmax=0.1):\r\n",
        "    plt.close('all')\r\n",
        "    plt.set_cmap('viridis')\r\n",
        "\r\n",
        "    # Visualize sparsity of A.\r\n",
        "    plt.imshow(hmm.A, vmax=1.0)\r\n",
        "    plt.colorbar()\r\n",
        "    plt.title('Sparsity of A matrix')\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "    # Visualize parsity of O.\r\n",
        "    plt.imshow(np.array(hmm.O)[:, :O_max_cols], vmax=O_vmax, aspect='auto')\r\n",
        "    plt.colorbar()\r\n",
        "    plt.title('Sparsity of O matrix')\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "\r\n",
        "####################\r\n",
        "# HMM ANIMATION FUNCTIONS\r\n",
        "####################\r\n",
        "\r\n",
        "def animate_emission(hmm, obs_map, M=8, height=12, width=12, delay=1):\r\n",
        "    # Parameters.\r\n",
        "    lim = 1200\r\n",
        "    text_x_offset = 40\r\n",
        "    text_y_offset = 80\r\n",
        "    x_offset = 580\r\n",
        "    y_offset = 520\r\n",
        "    R = 420\r\n",
        "    r = 100\r\n",
        "    arrow_size = 20\r\n",
        "    arrow_p1 = 0.03\r\n",
        "    arrow_p2 = 0.02\r\n",
        "    arrow_p3 = 0.06\r\n",
        "    \r\n",
        "    # Initialize.\r\n",
        "    n_states = len(hmm.A)\r\n",
        "    obs_map_r = obs_map_reverser(obs_map)\r\n",
        "    wordclouds = states_to_wordclouds(hmm, obs_map, max_words=20, show=False)\r\n",
        "\r\n",
        "    # Initialize plot.    \r\n",
        "    fig, ax = plt.subplots()\r\n",
        "    fig.set_figheight(height)\r\n",
        "    fig.set_figwidth(width)\r\n",
        "    ax.grid('off')\r\n",
        "    plt.axis('off')\r\n",
        "    ax.set_xlim([0, lim])\r\n",
        "    ax.set_ylim([0, lim])\r\n",
        "\r\n",
        "    # Plot each wordcloud.\r\n",
        "    for i, wordcloud in enumerate(wordclouds):\r\n",
        "        x = x_offset + int(R * np.cos(np.pi * 2 * i / n_states))\r\n",
        "        y = y_offset + int(R * np.sin(np.pi * 2 * i / n_states))\r\n",
        "        ax.imshow(wordcloud.to_array(), extent=(x - r, x + r, y - r, y + r), aspect='auto', zorder=-1)\r\n",
        "\r\n",
        "    # Initialize text.\r\n",
        "    text = ax.text(text_x_offset, lim - text_y_offset, '', fontsize=24)\r\n",
        "        \r\n",
        "    # Make the arrows.\r\n",
        "    zorder_mult = n_states ** 2 * 100\r\n",
        "    arrows = []\r\n",
        "    for i in range(n_states):\r\n",
        "        row = []\r\n",
        "        for j in range(n_states):\r\n",
        "            # Arrow coordinates.\r\n",
        "            x_i = x_offset + R * np.cos(np.pi * 2 * i / n_states)\r\n",
        "            y_i = y_offset + R * np.sin(np.pi * 2 * i / n_states)\r\n",
        "            x_j = x_offset + R * np.cos(np.pi * 2 * j / n_states)\r\n",
        "            y_j = y_offset + R * np.sin(np.pi * 2 * j / n_states)\r\n",
        "            \r\n",
        "            dx = x_j - x_i\r\n",
        "            dy = y_j - y_i\r\n",
        "            d = np.sqrt(dx**2 + dy**2)\r\n",
        "\r\n",
        "            if i != j:\r\n",
        "                arrow = ax.arrow(x_i + (r/d + arrow_p1) * dx + arrow_p2 * dy,\r\n",
        "                                 y_i + (r/d + arrow_p1) * dy + arrow_p2 * dx,\r\n",
        "                                 (1 - 2 * r/d - arrow_p3) * dx,\r\n",
        "                                 (1 - 2 * r/d - arrow_p3) * dy,\r\n",
        "                                 color=(1 - hmm.A[i][j], ) * 3,\r\n",
        "                                 head_width=arrow_size, head_length=arrow_size,\r\n",
        "                                 zorder=int(hmm.A[i][j] * zorder_mult))\r\n",
        "            else:\r\n",
        "                arrow = ax.arrow(x_i, y_i, 0, 0,\r\n",
        "                                 color=(1 - hmm.A[i][j], ) * 3,\r\n",
        "                                 head_width=arrow_size, head_length=arrow_size,\r\n",
        "                                 zorder=int(hmm.A[i][j] * zorder_mult))\r\n",
        "\r\n",
        "            row.append(arrow)\r\n",
        "        arrows.append(row)\r\n",
        "\r\n",
        "    emission, states = hmm.generate_emission(M)\r\n",
        "\r\n",
        "    def animate(i):\r\n",
        "        if i >= delay:\r\n",
        "            i -= delay\r\n",
        "\r\n",
        "            if i == 0:\r\n",
        "                arrows[states[0]][states[0]].set_color('red')\r\n",
        "            elif i == 1:\r\n",
        "                arrows[states[0]][states[0]].set_color((1 - hmm.A[states[0]][states[0]], ) * 3)\r\n",
        "                arrows[states[i - 1]][states[i]].set_color('red')\r\n",
        "            else:\r\n",
        "                arrows[states[i - 2]][states[i - 1]].set_color((1 - hmm.A[states[i - 2]][states[i - 1]], ) * 3)\r\n",
        "                arrows[states[i - 1]][states[i]].set_color('red')\r\n",
        "\r\n",
        "            # Set text.\r\n",
        "            text.set_text(' '.join([obs_map_r[e] for e in emission][:i+1]).capitalize())\r\n",
        "\r\n",
        "            return arrows + [text]\r\n",
        "\r\n",
        "    # Animate!\r\n",
        "    print('\\nAnimating...')\r\n",
        "    anim = FuncAnimation(fig, animate, frames=M+delay, interval=1000)\r\n",
        "\r\n",
        "    return anim"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zIXBL7AYzi_"
      },
      "source": [
        "Making the syllable dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmAsx0KXYnS3",
        "outputId": "1f1b9017-795d-4ecf-bec4-23b9b3feca9c"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/lakigigar/Caltech-CS155-2021/main/projects/project3/data/Syllable_dictionary.txt"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-06 07:13:10--  https://raw.githubusercontent.com/lakigigar/Caltech-CS155-2021/main/projects/project3/data/Syllable_dictionary.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33379 (33K) [text/plain]\n",
            "Saving to: ‘Syllable_dictionary.txt’\n",
            "\n",
            "\rSyllable_dictionary   0%[                    ]       0  --.-KB/s               \rSyllable_dictionary 100%[===================>]  32.60K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2021-03-06 07:13:10 (8.06 MB/s) - ‘Syllable_dictionary.txt’ saved [33379/33379]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt660eWVY4MX"
      },
      "source": [
        "import re\r\n",
        "with open('Syllable_dictionary.txt', \"r\") as f:\r\n",
        "  syl_data = f.readlines()\r\n",
        "  #dict_exp = dict(re.findall(r'(\\S+)\\s+(.+)', f.read()))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX66KB1SY6Ee"
      },
      "source": [
        "# remove all ' or \" and \\n\r\n",
        "# remove punctuation\r\n",
        "to_remove = ['-', \"'\"]\r\n",
        "for k in range(len(to_remove)):\r\n",
        "  for i in range(len(syl_data)):\r\n",
        "    syl_data[i] = ''.join([j for j in syl_data[i] if j not in to_remove])\r\n",
        "#print(syl_data[0])\r\n",
        "for i in range(len(syl_data)):\r\n",
        "  syl_data[i] = syl_data[i].replace('\\n', '')\r\n",
        "#print(syl_data[0])\r\n",
        "# split the lines into words\r\n",
        "for i in range(len(syl_data)):\r\n",
        "  syl_data[i] = re.findall(r\"[\\w']+|[.,?;]\", syl_data[i])\r\n",
        "#print(syl_data[0])\r\n",
        "# make syl_data a dictionary\r\n",
        "syl_dict = dict()\r\n",
        "for line in syl_data:\r\n",
        "  #print(line)\r\n",
        "  #import pdb; pdb.set_trace()\r\n",
        "  syl_dict.update({line[0]: [line[i] for i in range(1, len(line))]})"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqNDclgFY78W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}