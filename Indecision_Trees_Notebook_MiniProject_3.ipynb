{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Indecision_Trees_Notebook_MiniProject_3",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6789bf3cc97946569b2f25207179059c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0b6ed80acb504a47929a520430244ccf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_813e4b891d334858b86e64ebe92e7b8b",
              "IPY_MODEL_72a903585b554bd3bdf36003c3704879"
            ]
          }
        },
        "0b6ed80acb504a47929a520430244ccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "813e4b891d334858b86e64ebe92e7b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_86d3e9e38f484f458dd4bf2667e20bc3",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 20,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 20,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a42844ea47b34a3294b8e5e7ed889ac4"
          }
        },
        "72a903585b554bd3bdf36003c3704879": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b89a599cd4bd4166bce1c41afbc73051",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 20/20 [04:51&lt;00:00, 14.59s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6f83e8515db4921ab19cc6f2d08976e"
          }
        },
        "86d3e9e38f484f458dd4bf2667e20bc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a42844ea47b34a3294b8e5e7ed889ac4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b89a599cd4bd4166bce1c41afbc73051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6f83e8515db4921ab19cc6f2d08976e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0af71856de45444286d7f4abf62bbbdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_17f917189f64471b9b876b7703142452",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ef08d0e2295e4f69bf950621bb6cf0b5",
              "IPY_MODEL_6d63467299ad424b8032ec6386d5330f"
            ]
          }
        },
        "17f917189f64471b9b876b7703142452": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef08d0e2295e4f69bf950621bb6cf0b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_00f1ab8fa48b4d55b98b78d87dcd3d47",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 50,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 50,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f316cc55894947c5ba23b3d04c324630"
          }
        },
        "6d63467299ad424b8032ec6386d5330f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a01589e4ff024af193010f219ef1d9b0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 50/50 [53:32&lt;00:00, 64.25s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_845cffdb33e84731acb84fbc8863ac4e"
          }
        },
        "00f1ab8fa48b4d55b98b78d87dcd3d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f316cc55894947c5ba23b3d04c324630": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a01589e4ff024af193010f219ef1d9b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "845cffdb33e84731acb84fbc8863ac4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df1bc8c1b4004c31ac0a730b4ccae65d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_58a23c06292a46d285823237bc20b8ed",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bdbf4229b8a54d2aa087c3bf10f13fe9",
              "IPY_MODEL_da0030480bf2444981d9cf2d2f6434b0"
            ]
          }
        },
        "58a23c06292a46d285823237bc20b8ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bdbf4229b8a54d2aa087c3bf10f13fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0854589d6bc947c193a8766ec5144f49",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 50,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 50,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_910cbd561b194e3285bba4e89eee098f"
          }
        },
        "da0030480bf2444981d9cf2d2f6434b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d73bc972fc9a4c35aa154fff259f266d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 50/50 [16:01&lt;00:00, 19.24s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f8333e5d0f2e42c5a19bc1f8ec10786f"
          }
        },
        "0854589d6bc947c193a8766ec5144f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "910cbd561b194e3285bba4e89eee098f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d73bc972fc9a4c35aa154fff259f266d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f8333e5d0f2e42c5a19bc1f8ec10786f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35f371baad5b4a61a033ea6a52078efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1ec40b9de2e74a9f9d43cb3c3bbe383e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7cf05b769e1542baa5ea7179cb27b1ad",
              "IPY_MODEL_ec50b492c0c24bfab693efff8ad7ab18"
            ]
          }
        },
        "1ec40b9de2e74a9f9d43cb3c3bbe383e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7cf05b769e1542baa5ea7179cb27b1ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_624279bda8a64511a1e335230521d6fc",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 50,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 50,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0c6c251369c74125867efa75ab79768e"
          }
        },
        "ec50b492c0c24bfab693efff8ad7ab18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4198e6897cbf45baa2a1a8c4d15dff85",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 50/50 [09:43&lt;00:00, 11.67s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_04de8865e6ae4d61934256c7a85712a0"
          }
        },
        "624279bda8a64511a1e335230521d6fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0c6c251369c74125867efa75ab79768e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4198e6897cbf45baa2a1a8c4d15dff85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "04de8865e6ae4d61934256c7a85712a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "48233a5cdab9415ea9c6d82efa5b466c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6531af6dd72146f7a20f4828d59a6a68",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_518f0207927f48198fb8b85666641846",
              "IPY_MODEL_341ad478e2664620b4c2653e6d46fcf2"
            ]
          }
        },
        "6531af6dd72146f7a20f4828d59a6a68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "518f0207927f48198fb8b85666641846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1b34676f08ee419eaed42be2d16cd3ef",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 50,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 50,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2433be9fa2d14a0fb47c266cd308f3c6"
          }
        },
        "341ad478e2664620b4c2653e6d46fcf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ceb316dd152c4f4597953d4fb8b32d67",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 50/50 [02:11&lt;00:00,  2.63s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6dd8acf627145c4a85553c582ea5a6b"
          }
        },
        "1b34676f08ee419eaed42be2d16cd3ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2433be9fa2d14a0fb47c266cd308f3c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ceb316dd152c4f4597953d4fb8b32d67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6dd8acf627145c4a85553c582ea5a6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/treyra/CS155_miniproject3/blob/main/Indecision_Trees_Notebook_MiniProject_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqIVzr9fXRz3"
      },
      "source": [
        "#Data Pre-processing\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwUm54mhYliJ"
      },
      "source": [
        "import numpy as np\r\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CBwIp4TQYeT_",
        "outputId": "94d887dd-232b-4661-b5a3-83541aba8f64"
      },
      "source": [
        "# read in the data\n",
        "# Import Data\n",
        "data = np.genfromtxt('https://raw.githubusercontent.com/lakigigar/Caltech-CS155-2021/main/projects/project3/data/shakespeare.txt',delimiter='\\t',dtype=None,encoding='ISO-8859-1')\n",
        "data[-15]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'154'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWjzTm1TY-Us"
      },
      "source": [
        "# make all words lower case\n",
        "for i in range(len(data)):\n",
        "  data[i]=data[i].lower()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTZh0lAeajPB"
      },
      "source": [
        "# remove space at beginning of line\n",
        "for i in range(len(data)):\n",
        "  while data[i][0] == ' ':\n",
        "    line = list(data[i])\n",
        "    data[i] = \"\".join(line[1:len(line)])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faG6yVLGbrUK"
      },
      "source": [
        "# remove \\n\n",
        "for i in range(len(data)):\n",
        "        data[i] = data[i].replace('\\n', '')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFb9hQSUbz_d"
      },
      "source": [
        "# remove punctuation\n",
        "to_remove = ['.', ',', ';', ':', '?', '!', '-', \"'\",\"(\",\")\"]\n",
        "for k in range(len(to_remove)):\n",
        "  for i in range(len(data)):\n",
        "    data[i] = ''.join([j for j in data[i] if j not in to_remove])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WOHcW20X2sf"
      },
      "source": [
        "# remove empty lines\n",
        "# find indices to remove\n",
        "remove_idx = []\n",
        "for i in range(len(data)):\n",
        "  if data[i] == '\\n':\n",
        "    remove_idx.append(i)\n",
        "  if data[i] == '':\n",
        "    remove_idx.append(i)\n",
        "# remove\n",
        "data_clean = []\n",
        "for k in range(len(data)):\n",
        "  if k not in remove_idx:\n",
        "    data_clean.append(data[k])\n",
        "data = data_clean"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijE-a5WWdmi9",
        "outputId": "c7cd4a87-0733-463f-ea8c-d3d0a89656c8"
      },
      "source": [
        "# remove sonnets which are too long or too short\n",
        "# always 14 lines long\n",
        "# check how long each sonnet is - should be 14!\n",
        "digit_idxs = []\n",
        "for i in range(len(data)):\n",
        "  if data[i].isdigit():\n",
        "    digit_idxs.append(i)\n",
        "#print(digit_idxs)\n",
        "# get difference\n",
        "length = np.diff(np.array(digit_idxs))\n",
        "#print(length)\n",
        "# remove the sonnet with too many or too few lines\n",
        "remove_nbrs = dict()\n",
        "for i in range(len(length)):\n",
        "  if length[i]!=15:\n",
        "    remove_nbrs.update({data[digit_idxs[i]]:length[i]})\n",
        "# remove the sonnets with the numbers in remove_numbers\n",
        "remove_idx = []\n",
        "for i in range(len(data)):\n",
        "  if data[i] in remove_nbrs:\n",
        "    print(data[i])\n",
        "    for k in range(0,remove_nbrs[data[i]]):\n",
        "      remove_idx.append(i+k)\n",
        "# remove\n",
        "data_clean = []\n",
        "for k in range(len(data)):\n",
        "  if k not in remove_idx:\n",
        "    data_clean.append(data[k])\n",
        "data = data_clean"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99\n",
            "126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfeWb8KGYI4C"
      },
      "source": [
        "# remove numbers\n",
        "for i in range(len(data)):\n",
        "  data[i] = ''.join([j for j in data[i] if not j.isdigit()])\n",
        "# remove created empty lines again\n",
        "# find indices to remove\n",
        "remove_idx = []\n",
        "for i in range(len(data)):\n",
        "  if data[i] == '\\n':\n",
        "    remove_idx.append(i)\n",
        "  if data[i] == '':\n",
        "    remove_idx.append(i)\n",
        "# remove\n",
        "data_clean = []\n",
        "for k in range(len(data)):\n",
        "  if k not in remove_idx:\n",
        "    data_clean.append(data[k])\n",
        "data = data_clean"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDdcig86YOrb"
      },
      "source": [
        "# this is the data per line\n",
        "data_by_line = data"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZhwdlDLfaTK"
      },
      "source": [
        "# get data per sonnet\n",
        "# split up in sonnets\n",
        "nr_sonnets = len(data)/14\n",
        "data_by_sonnet = [None] * int(nr_sonnets)\n",
        "i = 0\n",
        "for k in range(0, len(data), 14):\n",
        "  cString = ''\n",
        "  for idx in range(14):\n",
        "    #print(idx)\n",
        "    if idx != 0:\n",
        "      try:\n",
        "        cString = cString + ' ' + data[k + idx]\n",
        "      except:\n",
        "        import pdb; pdb.set_trace()\n",
        "    else: \n",
        "      cString = data[k]\n",
        "  data_by_sonnet[i] = cString\n",
        "  i+=1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DluK2BGo6BYY",
        "outputId": "5965935b-464a-4f42-f858-dc307d57f5d0"
      },
      "source": [
        "# mount drive\r\n",
        "# save data by line and data by sonnet\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('./drive',force_remount=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at ./drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9dxC62XZSzC"
      },
      "source": [
        "# make new file for data per line\n",
        "with open('/content/drive/My Drive/CS155_miniproject_3/data_line.txt', 'w') as f:\n",
        "  for item in data_by_line:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY0xUd3KbjXB"
      },
      "source": [
        "# make new file for data per sonnet\n",
        "with open('/content/drive/My Drive/CS155_miniproject_3/data_sonnet.txt', 'w') as f:\n",
        "  for item in data_by_sonnet:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ibninVYXaKH"
      },
      "source": [
        "We can also load the pre-processed data directly as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR0TkrchXYb9"
      },
      "source": [
        "# load the data - for now from drive until we have repo\r\n",
        "# open existing text file\r\n",
        "data_sonnet_raw = np.genfromtxt('https://raw.githubusercontent.com/treyra/CS155_miniproject3/main/data/data_sonnet.txt',delimiter='\\t',dtype=None,encoding='ISO-8859-1')\r\n",
        "data_line = np.genfromtxt('https://raw.githubusercontent.com/treyra/CS155_miniproject3/main/data/data_line.txt',delimiter='\\t',dtype=None,encoding='ISO-8859-1')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_67hRGyojhRL"
      },
      "source": [
        "#HMM Model\r\n",
        "\r\n",
        "Based off of HW 6's solution code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYCseFowX1pv"
      },
      "source": [
        "class HiddenMarkovModel:\r\n",
        "    '''\r\n",
        "    Class implementation of Hidden Markov Models.\r\n",
        "    '''\r\n",
        "\r\n",
        "    def __init__(self, A, O):\r\n",
        "        '''\r\n",
        "        Initializes an HMM. Assumes the following:\r\n",
        "            - States and observations are integers starting from 0. \r\n",
        "            - There is a start state (see notes on A_start below). There\r\n",
        "              is no integer associated with the start state, only\r\n",
        "              probabilities in the vector A_start.\r\n",
        "            - There is no end state. \r\n",
        "        Arguments:\r\n",
        "            A:          Transition matrix with dimensions L x L.\r\n",
        "                        The (i, j)^th element is the probability of\r\n",
        "                        transitioning from state i to state j. Note that\r\n",
        "                        this does not include the starting probabilities.\r\n",
        "            O:          Observation matrix with dimensions L x D.\r\n",
        "                        The (i, j)^th element is the probability of\r\n",
        "                        emitting observation j given state i.\r\n",
        "        Parameters:\r\n",
        "            L:          Number of states.\r\n",
        "            D:          Number of observations.\r\n",
        "            \r\n",
        "            A:          The transition matrix.\r\n",
        "            \r\n",
        "            O:          The observation matrix.\r\n",
        "            \r\n",
        "            A_start:    Starting transition probabilities. The i^th element\r\n",
        "                        is the probability of transitioning from the start\r\n",
        "                        state to state i. For simplicity, we assume that\r\n",
        "                        this distribution is uniform.\r\n",
        "        '''\r\n",
        "\r\n",
        "        self.L = len(A)\r\n",
        "        self.D = len(O[0])\r\n",
        "        self.A = np.array(A)\r\n",
        "        self.O = np.array(O)\r\n",
        "        self.A_start = [1. / self.L for _ in range(self.L)]\r\n",
        "\r\n",
        "\r\n",
        "    def viterbi(self, x):\r\n",
        "        '''\r\n",
        "        Uses the Viterbi algorithm to find the max probability state \r\n",
        "        sequence corresponding to a given input sequence.\r\n",
        "        Arguments:\r\n",
        "            x:          Input sequence in the form of a list of length M,\r\n",
        "                        consisting of integers ranging from 0 to D - 1.\r\n",
        "        Returns:\r\n",
        "            max_seq:    Output sequence corresponding to x with the highest\r\n",
        "                        probability.\r\n",
        "        '''\r\n",
        "\r\n",
        "        M = len(x)      # Length of sequence.\r\n",
        "\r\n",
        "        # The (i, j)^th elements of probs and seqs are the max probability\r\n",
        "        # of the prefix of length i ending in state j and the prefix\r\n",
        "        # that gives this probability, respectively.\r\n",
        "        #\r\n",
        "        # For instance, probs[1][0] is the probability of the prefix of\r\n",
        "        # length 1 ending in state 0.\r\n",
        "        probs = [[0. for _ in range(self.L)] for _ in range(M + 1)]\r\n",
        "        seqs = [['' for _ in range(self.L)] for _ in range(M + 1)]\r\n",
        "\r\n",
        "        # Calculate initial prefixes and probabilities.\r\n",
        "        for curr in range(self.L):\r\n",
        "            probs[1][curr] = self.A_start[curr] * self.O[curr][x[0]]\r\n",
        "            seqs[1][curr] = str(curr)\r\n",
        "\r\n",
        "        # Calculate best prefixes and probabilities throughout sequence.\r\n",
        "        for t in range(2, M + 1):\r\n",
        "            # Iterate over all possible current states.\r\n",
        "            for curr in range(self.L):\r\n",
        "                max_prob = float(\"-inf\")\r\n",
        "                max_prefix = ''\r\n",
        "\r\n",
        "                # Iterate over all possible previous states to find one\r\n",
        "                # that would maximize the probability of the current state.\r\n",
        "                for prev in range(self.L):\r\n",
        "                    curr_prob = probs[t - 1][prev] \\\r\n",
        "                                * self.A[prev][curr] \\\r\n",
        "                                * self.O[curr][x[t - 1]]\r\n",
        "\r\n",
        "                    # Continually update max probability and prefix.\r\n",
        "                    if curr_prob >= max_prob:\r\n",
        "                        max_prob = curr_prob\r\n",
        "                        max_prefix = seqs[t - 1][prev]\r\n",
        "\r\n",
        "                # Store the max probability and prefix.\r\n",
        "                probs[t][curr] = max_prob\r\n",
        "                seqs[t][curr] = max_prefix + str(curr)\r\n",
        "\r\n",
        "        # Find the index of the max probability of a sequence ending in x^M\r\n",
        "        # and the corresponding output sequence.\r\n",
        "        max_i = max(enumerate(probs[-1]), key=lambda x: x[1])[0]\r\n",
        "        max_seq = seqs[-1][max_i]\r\n",
        "\r\n",
        "        return max_seq\r\n",
        "\r\n",
        "\r\n",
        "    def forward(self, x, normalize=False):\r\n",
        "        '''\r\n",
        "        Uses the forward algorithm to calculate the alpha probability\r\n",
        "        vectors corresponding to a given input sequence.\r\n",
        "        Arguments:\r\n",
        "            x:          Input sequence in the form of a list of length M,\r\n",
        "                        consisting of integers ranging from 0 to D - 1.\r\n",
        "            normalize:  Whether to normalize each set of alpha_j(i) vectors\r\n",
        "                        at each i. This is useful to avoid underflow in\r\n",
        "                        unsupervised learning.\r\n",
        "        Returns:\r\n",
        "            alphas:     Vector of alphas.\r\n",
        "                        The (i, j)^th element of alphas is alpha_j(i),\r\n",
        "                        i.e. the probability of observing prefix x^1:i\r\n",
        "                        and state y^i = j.\r\n",
        "                        e.g. alphas[1][0] corresponds to the probability\r\n",
        "                        of observing x^1:1, i.e. the first observation,\r\n",
        "                        given that y^1 = 0, i.e. the first state is 0.\r\n",
        "        '''\r\n",
        "\r\n",
        "        M = len(x)      # Length of sequence.\r\n",
        "        alphas = [[0. for _ in range(self.L)] for _ in range(M + 1)]\r\n",
        "\r\n",
        "        # Note that alpha_j(0) is already correct for all j's.\r\n",
        "        # Calculate alpha_j(1) for all j's.\r\n",
        "        for curr in range(self.L):\r\n",
        "            alphas[1][curr] = self.A_start[curr] * self.O[curr][x[0]]\r\n",
        "\r\n",
        "        # Calculate alphas throughout sequence.\r\n",
        "        for t in range(1, M):\r\n",
        "            # Iterate over all possible current states.\r\n",
        "            for curr in range(self.L):\r\n",
        "                prob = 0\r\n",
        "\r\n",
        "                # Iterate over all possible previous states to accumulate\r\n",
        "                # the probabilities of all paths from the start state to\r\n",
        "                # the current state.\r\n",
        "                for prev in range(self.L):\r\n",
        "                    prob += alphas[t][prev] \\\r\n",
        "                            * self.A[prev][curr] \\\r\n",
        "                            * self.O[curr][x[t]]\r\n",
        "\r\n",
        "                # Store the accumulated probability.\r\n",
        "                alphas[t + 1][curr] = prob\r\n",
        "\r\n",
        "            if normalize:\r\n",
        "                norm = sum(alphas[t + 1])\r\n",
        "                for curr in range(self.L):\r\n",
        "                    alphas[t + 1][curr] /= norm\r\n",
        "\r\n",
        "        return alphas\r\n",
        "\r\n",
        "\r\n",
        "    def backward(self, x, normalize=False):\r\n",
        "        '''\r\n",
        "        Uses the backward algorithm to calculate the beta probability\r\n",
        "        vectors corresponding to a given input sequence.\r\n",
        "        Arguments:\r\n",
        "            x:          Input sequence in the form of a list of length M,\r\n",
        "                        consisting of integers ranging from 0 to D - 1.\r\n",
        "            normalize:  Whether to normalize each set of alpha_j(i) vectors\r\n",
        "                        at each i. This is useful to avoid underflow in\r\n",
        "                        unsupervised learning.\r\n",
        "        Returns:\r\n",
        "            betas:      Vector of betas.\r\n",
        "                        The (i, j)^th element of betas is beta_j(i), i.e.\r\n",
        "                        the probability of observing prefix x^(i+1):M and\r\n",
        "                        state y^i = j.\r\n",
        "                        e.g. betas[M][0] corresponds to the probability\r\n",
        "                        of observing x^M+1:M, i.e. no observations,\r\n",
        "                        given that y^M = 0, i.e. the last state is 0.\r\n",
        "        '''\r\n",
        "\r\n",
        "        M = len(x)      # Length of sequence.\r\n",
        "        betas = [[0. for _ in range(self.L)] for _ in range(M + 1)]\r\n",
        "\r\n",
        "        # Initialize initial betas.\r\n",
        "        for curr in range(self.L):\r\n",
        "            betas[-1][curr] = 1\r\n",
        "\r\n",
        "        # Calculate betas throughout sequence.\r\n",
        "        for t in range(-1, -M - 1, -1):\r\n",
        "            # Iterate over all possible current states.\r\n",
        "            for curr in range(self.L):\r\n",
        "                prob = 0\r\n",
        "\r\n",
        "                # Iterate over all possible next states to accumulate\r\n",
        "                # the probabilities of all paths from the end state to\r\n",
        "                # the current state.\r\n",
        "                for nxt in range(self.L):\r\n",
        "                    if t == -M:\r\n",
        "                        prob += betas[t][nxt] \\\r\n",
        "                                * self.A_start[nxt] \\\r\n",
        "                                * self.O[nxt][x[t]]\r\n",
        "\r\n",
        "                    else:\r\n",
        "                        prob += betas[t][nxt] \\\r\n",
        "                                * self.A[curr][nxt] \\\r\n",
        "                                * self.O[nxt][x[t]]\r\n",
        "\r\n",
        "                # Store the accumulated probability.\r\n",
        "                betas[t - 1][curr] = prob\r\n",
        "\r\n",
        "            if normalize:\r\n",
        "                norm = sum(betas[t - 1])\r\n",
        "                for curr in range(self.L):\r\n",
        "                    betas[t - 1][curr] /= norm\r\n",
        "\r\n",
        "        return betas\r\n",
        "\r\n",
        "\r\n",
        "    def supervised_learning(self, X, Y):\r\n",
        "        '''\r\n",
        "        Trains the HMM using the Maximum Likelihood closed form solutions\r\n",
        "        for the transition and observation matrices on a labeled\r\n",
        "        datset (X, Y). Note that this method does not return anything, but\r\n",
        "        instead updates the attributes of the HMM object.\r\n",
        "        Arguments:\r\n",
        "            X:          A dataset consisting of input sequences in the form\r\n",
        "                        of lists of variable length, consisting of integers \r\n",
        "                        ranging from 0 to D - 1. In other words, a list of\r\n",
        "                        lists.\r\n",
        "            Y:          A dataset consisting of state sequences in the form\r\n",
        "                        of lists of variable length, consisting of integers \r\n",
        "                        ranging from 0 to L - 1. In other words, a list of\r\n",
        "                        lists.\r\n",
        "                        Note that the elements in X line up with those in Y.\r\n",
        "        '''\r\n",
        "\r\n",
        "        # Calculate each element of A using the M-step formulas.\r\n",
        "        for curr in range(self.L):\r\n",
        "            for nxt in range(self.L):\r\n",
        "                num = 0.\r\n",
        "                den = 0.\r\n",
        "\r\n",
        "                for i in range(len(X)):\r\n",
        "                    x = X[i]\r\n",
        "                    y = Y[i]\r\n",
        "                    M = len(x)\r\n",
        "        \r\n",
        "                    num += len([1 for i in range(M - 1) \\\r\n",
        "                                if y[i] == curr and y[i + 1] == nxt])\r\n",
        "                    den += len([1 for i in range(M - 1) if y[i] == curr])\r\n",
        "\r\n",
        "                self.A[curr][nxt] = num / den\r\n",
        "\r\n",
        "        # Calculate each element of O using the M-step formulas.\r\n",
        "        for curr in range(self.L):\r\n",
        "            for xt in range(self.D):\r\n",
        "                num = 0.\r\n",
        "                den = 0.\r\n",
        "\r\n",
        "                for i in range(len(X)):\r\n",
        "                    x = X[i]\r\n",
        "                    y = Y[i]\r\n",
        "                    M = len(x)\r\n",
        "        \r\n",
        "                    num += len([1 for i in range(M) \\\r\n",
        "                                if y[i] == curr and x[i] == xt])\r\n",
        "                    den += len([1 for i in range(M) if y[i] == curr])\r\n",
        "\r\n",
        "                self.O[curr][xt] = num / den\r\n",
        "\r\n",
        "\r\n",
        "    def unsupervised_learning(self, X, N_iters):\r\n",
        "        '''\r\n",
        "        Trains the HMM using the Baum-Welch algorithm on an unlabeled\r\n",
        "        datset X. Note that this method does not return anything, but\r\n",
        "        instead updates the attributes of the HMM object.\r\n",
        "        Arguments:\r\n",
        "            X:          A dataset consisting of input sequences in the form\r\n",
        "                        of lists of length M, consisting of integers ranging\r\n",
        "                        from 0 to D - 1. In other words, a list of lists.\r\n",
        "            N_iters:    The number of iterations to train on.\r\n",
        "        '''\r\n",
        "\r\n",
        "        # Note that a comment starting with 'E' refers to the fact that\r\n",
        "        # the code under the comment is part of the E-step.\r\n",
        "\r\n",
        "        # Similarly, a comment starting with 'M' refers to the fact that\r\n",
        "        # the code under the comment is part of the M-step.\r\n",
        "\r\n",
        "        for iteration in tqdm(range(1, N_iters + 1)):\r\n",
        "            if iteration % 10 == 0:\r\n",
        "                print(\"Iteration: \" + str(iteration))\r\n",
        "\r\n",
        "            # Numerator and denominator for the update terms of A and O.\r\n",
        "            A_num = [[0. for i in range(self.L)] for j in range(self.L)]\r\n",
        "            O_num = [[0. for i in range(self.D)] for j in range(self.L)]\r\n",
        "            A_den = [0. for i in range(self.L)]\r\n",
        "            O_den = [0. for i in range(self.L)]\r\n",
        "\r\n",
        "            # For each input sequence:\r\n",
        "            for x in X:\r\n",
        "                M = len(x)\r\n",
        "                # Compute the alpha and beta probability vectors.\r\n",
        "                alphas = self.forward(x, normalize=True)\r\n",
        "                betas = self.backward(x, normalize=True)\r\n",
        "\r\n",
        "                # E: Update the expected observation probabilities for a\r\n",
        "                # given (x, y).\r\n",
        "                # The i^th index is P(y^t = i, x).\r\n",
        "                for t in range(1, M + 1):\r\n",
        "                    P_curr = [0. for _ in range(self.L)]\r\n",
        "                    \r\n",
        "                    for curr in range(self.L):\r\n",
        "                        P_curr[curr] = alphas[t][curr] * betas[t][curr]\r\n",
        "\r\n",
        "                    # Normalize the probabilities.\r\n",
        "                    norm = sum(P_curr)\r\n",
        "                    for curr in range(len(P_curr)):\r\n",
        "                        P_curr[curr] /= norm\r\n",
        "\r\n",
        "                    for curr in range(self.L):\r\n",
        "                        if t != M:\r\n",
        "                            A_den[curr] += P_curr[curr]\r\n",
        "                        O_den[curr] += P_curr[curr]\r\n",
        "                        O_num[curr][x[t - 1]] += P_curr[curr]\r\n",
        "\r\n",
        "                # E: Update the expectedP(y^j = a, y^j+1 = b, x) for given (x, y)\r\n",
        "                for t in range(1, M):\r\n",
        "                    P_curr_nxt = [[0. for _ in range(self.L)] for _ in range(self.L)]\r\n",
        "\r\n",
        "                    for curr in range(self.L):\r\n",
        "                        for nxt in range(self.L):\r\n",
        "                            P_curr_nxt[curr][nxt] = alphas[t][curr] \\\r\n",
        "                                                    * self.A[curr][nxt] \\\r\n",
        "                                                    * self.O[nxt][x[t]] \\\r\n",
        "                                                    * betas[t + 1][nxt]\r\n",
        "\r\n",
        "                    # Normalize:\r\n",
        "                    norm = 0\r\n",
        "                    for lst in P_curr_nxt:\r\n",
        "                        norm += sum(lst)\r\n",
        "                    for curr in range(self.L):\r\n",
        "                        for nxt in range(self.L):\r\n",
        "                            P_curr_nxt[curr][nxt] /= norm\r\n",
        "\r\n",
        "                    # Update A_num\r\n",
        "                    for curr in range(self.L):\r\n",
        "                        for nxt in range(self.L):\r\n",
        "                            A_num[curr][nxt] += P_curr_nxt[curr][nxt]\r\n",
        "\r\n",
        "            for curr in range(self.L):\r\n",
        "                for nxt in range(self.L):\r\n",
        "                    self.A[curr][nxt] = A_num[curr][nxt] / A_den[curr]\r\n",
        "\r\n",
        "            for curr in range(self.L):\r\n",
        "                for xt in range(self.D):\r\n",
        "                    self.O[curr][xt] = O_num[curr][xt] / O_den[curr]\r\n",
        "\r\n",
        "    def generate_emission(self, M):\r\n",
        "        '''\r\n",
        "        Generates an emission of length M, assuming that the starting state\r\n",
        "        is chosen uniformly at random. \r\n",
        "        Arguments:\r\n",
        "            M:          Length of the emission to generate.\r\n",
        "        Returns:\r\n",
        "            emission:   The randomly generated emission as a list.\r\n",
        "            states:     The randomly generated states as a list.\r\n",
        "        '''\r\n",
        "\r\n",
        "        emission = []\r\n",
        "        state = random.choice(range(self.L))\r\n",
        "        states = []\r\n",
        "\r\n",
        "        for t in range(M):\r\n",
        "            # Append state.\r\n",
        "            states.append(state)\r\n",
        "\r\n",
        "            # Sample next observation.\r\n",
        "            rand_var = random.uniform(0, 1)\r\n",
        "            next_obs = 0\r\n",
        "\r\n",
        "            while rand_var > 0:\r\n",
        "                rand_var -= self.O[state][next_obs]\r\n",
        "                next_obs += 1\r\n",
        "\r\n",
        "            next_obs -= 1\r\n",
        "            emission.append(next_obs)\r\n",
        "\r\n",
        "            # Sample next state.\r\n",
        "            rand_var = random.uniform(0, 1)\r\n",
        "            next_state = 0\r\n",
        "\r\n",
        "            while rand_var > 0:\r\n",
        "                rand_var -= self.A[state][next_state]\r\n",
        "                next_state += 1\r\n",
        "\r\n",
        "            next_state -= 1\r\n",
        "            state = next_state\r\n",
        "\r\n",
        "        return emission, states\r\n",
        "\r\n",
        "\r\n",
        "    def probability_alphas(self, x):\r\n",
        "        '''\r\n",
        "        Finds the maximum probability of a given input sequence using\r\n",
        "        the forward algorithm.\r\n",
        "        Arguments:\r\n",
        "            x:          Input sequence in the form of a list of length M,\r\n",
        "                        consisting of integers ranging from 0 to D - 1.\r\n",
        "        Returns:\r\n",
        "            prob:       Total probability that x can occur.\r\n",
        "        '''\r\n",
        "\r\n",
        "        # Calculate alpha vectors.\r\n",
        "        alphas = self.forward(x)\r\n",
        "\r\n",
        "        # alpha_j(M) gives the probability that the output sequence ends\r\n",
        "        # in j. Summing this value over all possible states j gives the\r\n",
        "        # total probability of x paired with any output sequence, i.e. the\r\n",
        "        # probability of x.\r\n",
        "        prob = sum(alphas[-1])\r\n",
        "        return prob\r\n",
        "\r\n",
        "\r\n",
        "    def probability_betas(self, x):\r\n",
        "        '''\r\n",
        "        Finds the maximum probability of a given input sequence using\r\n",
        "        the backward algorithm.\r\n",
        "        Arguments:\r\n",
        "            x:          Input sequence in the form of a list of length M,\r\n",
        "                        consisting of integers ranging from 0 to D - 1.\r\n",
        "        Returns:\r\n",
        "            prob:       Total probability that x can occur.\r\n",
        "        '''\r\n",
        "\r\n",
        "        betas = self.backward(x)\r\n",
        "\r\n",
        "        # beta_j(0) gives the probability of the output sequence. Summing\r\n",
        "        # this over all states and then normalizing gives the total\r\n",
        "        # probability of x paired with any output sequence, i.e. the\r\n",
        "        # probability of x.\r\n",
        "        prob = sum([betas[1][k] * self.A_start[k] * self.O[k][x[0]] \\\r\n",
        "            for k in range(self.L)])\r\n",
        "\r\n",
        "        return prob\r\n",
        "\r\n",
        "\r\n",
        "def supervised_HMM(X, Y):\r\n",
        "    '''\r\n",
        "    Helper function to train a supervised HMM. The function determines the\r\n",
        "    number of unique states and observations in the given data, initializes\r\n",
        "    the transition and observation matrices, creates the HMM, and then runs\r\n",
        "    the training function for supervised learning.\r\n",
        "    Arguments:\r\n",
        "        X:          A dataset consisting of input sequences in the form\r\n",
        "                    of lists of variable length, consisting of integers \r\n",
        "                    ranging from 0 to D - 1. In other words, a list of lists.\r\n",
        "        Y:          A dataset consisting of state sequences in the form\r\n",
        "                    of lists of variable length, consisting of integers \r\n",
        "                    ranging from 0 to L - 1. In other words, a list of lists.\r\n",
        "                    Note that the elements in X line up with those in Y.\r\n",
        "    '''\r\n",
        "\r\n",
        "    # Make a set of observations.\r\n",
        "    observations = set()\r\n",
        "    for x in X:\r\n",
        "        observations |= set(x)\r\n",
        "\r\n",
        "    # Make a set of states.\r\n",
        "    states = set()\r\n",
        "    for y in Y:\r\n",
        "        states |= set(y)\r\n",
        "    \r\n",
        "    # Compute L and D.\r\n",
        "    L = len(states)\r\n",
        "    D = len(observations)\r\n",
        "\r\n",
        "    # Randomly initialize and normalize matrices A and O.\r\n",
        "    A = [[random.random() for i in range(L)] for j in range(L)]\r\n",
        "\r\n",
        "    for i in range(len(A)):\r\n",
        "        norm = sum(A[i])\r\n",
        "        for j in range(len(A[i])):\r\n",
        "            A[i][j] /= norm\r\n",
        "    \r\n",
        "    O = [[random.random() for i in range(D)] for j in range(L)]\r\n",
        "\r\n",
        "    for i in range(len(O)):\r\n",
        "        norm = sum(O[i])\r\n",
        "        for j in range(len(O[i])):\r\n",
        "            O[i][j] /= norm\r\n",
        "\r\n",
        "    # Train an HMM with labeled data.\r\n",
        "    HMM = HiddenMarkovModel(A, O)\r\n",
        "    HMM.supervised_learning(X, Y)\r\n",
        "\r\n",
        "    return HMM\r\n",
        "\r\n",
        "\r\n",
        "def unsupervised_HMM(X, n_states, N_iters,rng=np.random.RandomState(1)):\r\n",
        "    '''\r\n",
        "    Helper function to train an unsupervised HMM. The function determines the\r\n",
        "    number of unique observations in the given data, initializes\r\n",
        "    the transition and observation matrices, creates the HMM, and then runs\r\n",
        "    the training function for unsupervised learing.\r\n",
        "    Arguments:\r\n",
        "        X:          A dataset consisting of input sequences in the form\r\n",
        "                    of lists of variable length, consisting of integers \r\n",
        "                    ranging from 0 to D - 1. In other words, a list of lists.\r\n",
        "        n_states:   Number of hidden states to use in training.\r\n",
        "        \r\n",
        "        N_iters:    The number of iterations to train on.\r\n",
        "        rng:        The random number generator for reproducible result.\r\n",
        "                    Default to RandomState(1).\r\n",
        "    '''\r\n",
        "\r\n",
        "    # Make a set of observations.\r\n",
        "    observations = set()\r\n",
        "    for x in X:\r\n",
        "        observations |= set(x)\r\n",
        "    \r\n",
        "    # Compute L and D.\r\n",
        "    L = n_states\r\n",
        "    D = len(observations)\r\n",
        "\r\n",
        "    # Randomly initialize and normalize matrices A.\r\n",
        "    A = [[rng.random() for i in range(L)] for j in range(L)]\r\n",
        "\r\n",
        "    for i in range(len(A)):\r\n",
        "        norm = sum(A[i])\r\n",
        "        for j in range(len(A[i])):\r\n",
        "            A[i][j] /= norm\r\n",
        "    \r\n",
        "    # Randomly initialize and normalize matrix O.\r\n",
        "    O = [[rng.random() for i in range(D)] for j in range(L)]\r\n",
        "\r\n",
        "    for i in range(len(O)):\r\n",
        "        norm = sum(O[i])\r\n",
        "        for j in range(len(O[i])):\r\n",
        "            O[i][j] /= norm\r\n",
        "\r\n",
        "    # Train an HMM with unlabeled data.\r\n",
        "    HMM = HiddenMarkovModel(A, O)\r\n",
        "    HMM.unsupervised_learning(X, N_iters)\r\n",
        "\r\n",
        "    return HMM"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXMxhK5HYmzu"
      },
      "source": [
        "########################################\r\n",
        "# CS/CNS/EE 155 2018\r\n",
        "# Problem Set 6\r\n",
        "#\r\n",
        "# Author:       Andrew Kang\r\n",
        "# Description:  Set 6 HMM helper\r\n",
        "########################################\r\n",
        "\r\n",
        "import re\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from wordcloud import WordCloud\r\n",
        "from matplotlib import animation\r\n",
        "from matplotlib.animation import FuncAnimation\r\n",
        "\r\n",
        "\r\n",
        "####################\r\n",
        "# WORDCLOUD FUNCTIONS\r\n",
        "####################\r\n",
        "\r\n",
        "def mask():\r\n",
        "    # Parameters.\r\n",
        "    r = 128\r\n",
        "    d = 2 * r + 1\r\n",
        "\r\n",
        "    # Get points in a circle.\r\n",
        "    y, x = np.ogrid[-r:d-r, -r:d-r]\r\n",
        "    circle = (x**2 + y**2 <= r**2)\r\n",
        "\r\n",
        "    # Create mask.\r\n",
        "    mask = 255 * np.ones((d, d), dtype=np.uint8)\r\n",
        "    mask[circle] = 0\r\n",
        "\r\n",
        "    return mask\r\n",
        "\r\n",
        "def text_to_wordcloud(text, max_words=50, title='', show=True):\r\n",
        "    plt.close('all')\r\n",
        "\r\n",
        "    # Generate a wordcloud image.\r\n",
        "    wordcloud = WordCloud(random_state=0,\r\n",
        "                          max_words=max_words,\r\n",
        "                          background_color='white',\r\n",
        "                          mask=mask()).generate(text)\r\n",
        "\r\n",
        "    # Show the image.\r\n",
        "    if show:\r\n",
        "        plt.imshow(wordcloud, interpolation='bilinear')\r\n",
        "        plt.axis('off')\r\n",
        "        plt.title(title, fontsize=24)\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "    return wordcloud\r\n",
        "\r\n",
        "def states_to_wordclouds(hmm, obs_map, max_words=50, show=True):\r\n",
        "    # Initialize.\r\n",
        "    M = 100000\r\n",
        "    n_states = len(hmm.A)\r\n",
        "    obs_map_r = obs_map_reverser(obs_map)\r\n",
        "    wordclouds = []\r\n",
        "\r\n",
        "    # Generate a large emission.\r\n",
        "    emission, states = hmm.generate_emission(M)\r\n",
        "\r\n",
        "    # For each state, get a list of observations that have been emitted\r\n",
        "    # from that state.\r\n",
        "    obs_count = []\r\n",
        "    for i in range(n_states):\r\n",
        "        obs_lst = np.array(emission)[np.where(np.array(states) == i)[0]]\r\n",
        "        obs_count.append(obs_lst)\r\n",
        "\r\n",
        "    # For each state, convert it into a wordcloud.\r\n",
        "    for i in range(n_states):\r\n",
        "        obs_lst = obs_count[i]\r\n",
        "        sentence = [obs_map_r[j] for j in obs_lst]\r\n",
        "        sentence_str = ' '.join(sentence)\r\n",
        "\r\n",
        "        wordclouds.append(text_to_wordcloud(sentence_str, max_words=max_words, title='State %d' % i, show=show))\r\n",
        "\r\n",
        "    return wordclouds\r\n",
        "\r\n",
        "\r\n",
        "####################\r\n",
        "# HMM FUNCTIONS\r\n",
        "####################\r\n",
        "\r\n",
        "def parse_observations(text):\r\n",
        "    # Convert text to dataset.\r\n",
        "    lines = [line.split() for line in text.split('\\n') if line.split()]\r\n",
        "\r\n",
        "    obs_counter = 0\r\n",
        "    obs = []\r\n",
        "    obs_map = {}\r\n",
        "\r\n",
        "    for line in lines:\r\n",
        "        obs_elem = []\r\n",
        "        \r\n",
        "        for word in line:\r\n",
        "            word = re.sub(r'[^\\w]', '', word).lower()\r\n",
        "            if word not in obs_map:\r\n",
        "                # Add unique words to the observations map.\r\n",
        "                obs_map[word] = obs_counter\r\n",
        "                obs_counter += 1\r\n",
        "            \r\n",
        "            # Add the encoded word.\r\n",
        "            obs_elem.append(obs_map[word])\r\n",
        "        \r\n",
        "        # Add the encoded sequence.\r\n",
        "        obs.append(obs_elem)\r\n",
        "\r\n",
        "    return obs, obs_map\r\n",
        "\r\n",
        "def obs_map_reverser(obs_map):\r\n",
        "    obs_map_r = {}\r\n",
        "\r\n",
        "    for key in obs_map:\r\n",
        "        obs_map_r[obs_map[key]] = key\r\n",
        "\r\n",
        "    return obs_map_r\r\n",
        "\r\n",
        "def sample_sentence(hmm, obs_map, n_words=100):\r\n",
        "    # Get reverse map.\r\n",
        "    obs_map_r = obs_map_reverser(obs_map)\r\n",
        "\r\n",
        "    # Sample and convert sentence.\r\n",
        "    emission, states = hmm.generate_emission(n_words)\r\n",
        "    sentence = [obs_map_r[i] for i in emission]\r\n",
        "\r\n",
        "    return ' '.join(sentence).capitalize() + '...'\r\n",
        "\r\n",
        "\r\n",
        "####################\r\n",
        "# HMM VISUALIZATION FUNCTIONS\r\n",
        "####################\r\n",
        "\r\n",
        "def visualize_sparsities(hmm, O_max_cols=50, O_vmax=0.1):\r\n",
        "    plt.close('all')\r\n",
        "    plt.set_cmap('viridis')\r\n",
        "\r\n",
        "    # Visualize sparsity of A.\r\n",
        "    plt.imshow(hmm.A, vmax=1.0)\r\n",
        "    plt.colorbar()\r\n",
        "    plt.title('Sparsity of A matrix')\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "    # Visualize parsity of O.\r\n",
        "    plt.imshow(np.array(hmm.O)[:, :O_max_cols], vmax=O_vmax, aspect='auto')\r\n",
        "    plt.colorbar()\r\n",
        "    plt.title('Sparsity of O matrix')\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "\r\n",
        "####################\r\n",
        "# HMM ANIMATION FUNCTIONS\r\n",
        "####################\r\n",
        "\r\n",
        "def animate_emission(hmm, obs_map, M=8, height=12, width=12, delay=1):\r\n",
        "    # Parameters.\r\n",
        "    lim = 1200\r\n",
        "    text_x_offset = 40\r\n",
        "    text_y_offset = 80\r\n",
        "    x_offset = 580\r\n",
        "    y_offset = 520\r\n",
        "    R = 420\r\n",
        "    r = 100\r\n",
        "    arrow_size = 20\r\n",
        "    arrow_p1 = 0.03\r\n",
        "    arrow_p2 = 0.02\r\n",
        "    arrow_p3 = 0.06\r\n",
        "    \r\n",
        "    # Initialize.\r\n",
        "    n_states = len(hmm.A)\r\n",
        "    obs_map_r = obs_map_reverser(obs_map)\r\n",
        "    wordclouds = states_to_wordclouds(hmm, obs_map, max_words=20, show=False)\r\n",
        "\r\n",
        "    # Initialize plot.    \r\n",
        "    fig, ax = plt.subplots()\r\n",
        "    fig.set_figheight(height)\r\n",
        "    fig.set_figwidth(width)\r\n",
        "    ax.grid('off')\r\n",
        "    plt.axis('off')\r\n",
        "    ax.set_xlim([0, lim])\r\n",
        "    ax.set_ylim([0, lim])\r\n",
        "\r\n",
        "    # Plot each wordcloud.\r\n",
        "    for i, wordcloud in enumerate(wordclouds):\r\n",
        "        x = x_offset + int(R * np.cos(np.pi * 2 * i / n_states))\r\n",
        "        y = y_offset + int(R * np.sin(np.pi * 2 * i / n_states))\r\n",
        "        ax.imshow(wordcloud.to_array(), extent=(x - r, x + r, y - r, y + r), aspect='auto', zorder=-1)\r\n",
        "\r\n",
        "    # Initialize text.\r\n",
        "    text = ax.text(text_x_offset, lim - text_y_offset, '', fontsize=24)\r\n",
        "        \r\n",
        "    # Make the arrows.\r\n",
        "    zorder_mult = n_states ** 2 * 100\r\n",
        "    arrows = []\r\n",
        "    for i in range(n_states):\r\n",
        "        row = []\r\n",
        "        for j in range(n_states):\r\n",
        "            # Arrow coordinates.\r\n",
        "            x_i = x_offset + R * np.cos(np.pi * 2 * i / n_states)\r\n",
        "            y_i = y_offset + R * np.sin(np.pi * 2 * i / n_states)\r\n",
        "            x_j = x_offset + R * np.cos(np.pi * 2 * j / n_states)\r\n",
        "            y_j = y_offset + R * np.sin(np.pi * 2 * j / n_states)\r\n",
        "            \r\n",
        "            dx = x_j - x_i\r\n",
        "            dy = y_j - y_i\r\n",
        "            d = np.sqrt(dx**2 + dy**2)\r\n",
        "\r\n",
        "            if i != j:\r\n",
        "                arrow = ax.arrow(x_i + (r/d + arrow_p1) * dx + arrow_p2 * dy,\r\n",
        "                                 y_i + (r/d + arrow_p1) * dy + arrow_p2 * dx,\r\n",
        "                                 (1 - 2 * r/d - arrow_p3) * dx,\r\n",
        "                                 (1 - 2 * r/d - arrow_p3) * dy,\r\n",
        "                                 color=(1 - hmm.A[i][j], ) * 3,\r\n",
        "                                 head_width=arrow_size, head_length=arrow_size,\r\n",
        "                                 zorder=int(hmm.A[i][j] * zorder_mult))\r\n",
        "            else:\r\n",
        "                arrow = ax.arrow(x_i, y_i, 0, 0,\r\n",
        "                                 color=(1 - hmm.A[i][j], ) * 3,\r\n",
        "                                 head_width=arrow_size, head_length=arrow_size,\r\n",
        "                                 zorder=int(hmm.A[i][j] * zorder_mult))\r\n",
        "\r\n",
        "            row.append(arrow)\r\n",
        "        arrows.append(row)\r\n",
        "\r\n",
        "    emission, states = hmm.generate_emission(M)\r\n",
        "\r\n",
        "    def animate(i):\r\n",
        "        if i >= delay:\r\n",
        "            i -= delay\r\n",
        "\r\n",
        "            if i == 0:\r\n",
        "                arrows[states[0]][states[0]].set_color('red')\r\n",
        "            elif i == 1:\r\n",
        "                arrows[states[0]][states[0]].set_color((1 - hmm.A[states[0]][states[0]], ) * 3)\r\n",
        "                arrows[states[i - 1]][states[i]].set_color('red')\r\n",
        "            else:\r\n",
        "                arrows[states[i - 2]][states[i - 1]].set_color((1 - hmm.A[states[i - 2]][states[i - 1]], ) * 3)\r\n",
        "                arrows[states[i - 1]][states[i]].set_color('red')\r\n",
        "\r\n",
        "            # Set text.\r\n",
        "            text.set_text(' '.join([obs_map_r[e] for e in emission][:i+1]).capitalize())\r\n",
        "\r\n",
        "            return arrows + [text]\r\n",
        "\r\n",
        "    # Animate!\r\n",
        "    print('\\nAnimating...')\r\n",
        "    anim = FuncAnimation(fig, animate, frames=M+delay, interval=1000)\r\n",
        "\r\n",
        "    return anim"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zIXBL7AYzi_"
      },
      "source": [
        "Making the syllable dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmAsx0KXYnS3",
        "outputId": "344ff348-4781-48bf-a543-0419032a9716"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/lakigigar/Caltech-CS155-2021/main/projects/project3/data/Syllable_dictionary.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-09 18:29:02--  https://raw.githubusercontent.com/lakigigar/Caltech-CS155-2021/main/projects/project3/data/Syllable_dictionary.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33379 (33K) [text/plain]\n",
            "Saving to: â€˜Syllable_dictionary.txtâ€™\n",
            "\n",
            "\rSyllable_dictionary   0%[                    ]       0  --.-KB/s               \rSyllable_dictionary 100%[===================>]  32.60K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-03-09 18:29:02 (32.3 MB/s) - â€˜Syllable_dictionary.txtâ€™ saved [33379/33379]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt660eWVY4MX"
      },
      "source": [
        "import re\r\n",
        "with open('Syllable_dictionary.txt', \"r\") as f:\r\n",
        "  syl_data = f.readlines()\r\n",
        "  #dict_exp = dict(re.findall(r'(\\S+)\\s+(.+)', f.read()))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX66KB1SY6Ee"
      },
      "source": [
        "# remove all ' or \" and \\n\r\n",
        "# remove punctuation\r\n",
        "to_remove = ['-', \"'\"]\r\n",
        "for k in range(len(to_remove)):\r\n",
        "  for i in range(len(syl_data)):\r\n",
        "    syl_data[i] = ''.join([j for j in syl_data[i] if j not in to_remove])\r\n",
        "#print(syl_data[0])\r\n",
        "for i in range(len(syl_data)):\r\n",
        "  syl_data[i] = syl_data[i].replace('\\n', '')\r\n",
        "#print(syl_data[0])\r\n",
        "# split the lines into words\r\n",
        "for i in range(len(syl_data)):\r\n",
        "  syl_data[i] = re.findall(r\"[\\w']+|[.,?;]\", syl_data[i])\r\n",
        "#print(syl_data[0])\r\n",
        "# make syl_data a dictionary\r\n",
        "syl_dict = dict()\r\n",
        "for line in syl_data:\r\n",
        "  #print(line)\r\n",
        "  #import pdb; pdb.set_trace()\r\n",
        "  syl_dict.update({line[0]: [line[i] for i in range(1, len(line))]})"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pspO08g0pnp8"
      },
      "source": [
        "# Generate Random Sonnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wcoLHaYp3sE"
      },
      "source": [
        "First input data and train HMM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Osu_bDsKOkf"
      },
      "source": [
        "Modify raw text data into data we can use for our syllable dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsWn1o3rI1Z1"
      },
      "source": [
        "data_sonnet = [[]]\r\n",
        "for i,sonnet in enumerate(data_sonnet_raw):\r\n",
        "    data_sonnet[i] = sonnet.split()\r\n",
        "    if i != len(data_sonnet_raw)-1:\r\n",
        "        data_sonnet.append([])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdN2DOoIp2U8"
      },
      "source": [
        "# create obs map\r\n",
        "count = 0\r\n",
        "obs = []\r\n",
        "obs_map = {}\r\n",
        "\r\n",
        "for line in data_sonnet:\r\n",
        "  obs_line = []\r\n",
        "  for word in line:\r\n",
        "    if word not in obs_map:\r\n",
        "      # add new words to the map\r\n",
        "      obs_map[word] = count\r\n",
        "      count += 1\r\n",
        "    # add the encoded words to the line map\r\n",
        "    obs_line.append(obs_map[word])\r\n",
        "      \r\n",
        "    # add the encoded sequence\r\n",
        "  obs.append(obs_line)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "6789bf3cc97946569b2f25207179059c",
            "0b6ed80acb504a47929a520430244ccf",
            "813e4b891d334858b86e64ebe92e7b8b",
            "72a903585b554bd3bdf36003c3704879",
            "86d3e9e38f484f458dd4bf2667e20bc3",
            "a42844ea47b34a3294b8e5e7ed889ac4",
            "b89a599cd4bd4166bce1c41afbc73051",
            "d6f83e8515db4921ab19cc6f2d08976e"
          ]
        },
        "id": "62otmV9jp6TE",
        "outputId": "9d70a687-0321-4112-ff2c-e848c9074a63"
      },
      "source": [
        "# train a HMM (only a few epochs)\r\n",
        "hmm8 = unsupervised_HMM(obs, 8, 20)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6789bf3cc97946569b2f25207179059c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 10\n",
            "Iteration: 20\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNoKKbNZ07cQ",
        "outputId": "53597e0f-19f3-459c-d0b3-51ea133a22ba"
      },
      "source": [
        "print(obs_map)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'from': 0, 'fairest': 1, 'creatures': 2, 'we': 3, 'desire': 4, 'increase': 5, 'that': 6, 'thereby': 7, 'beautys': 8, 'rose': 9, 'might': 10, 'never': 11, 'die': 12, 'but': 13, 'as': 14, 'the': 15, 'riper': 16, 'should': 17, 'by': 18, 'time': 19, 'decease': 20, 'his': 21, 'tender': 22, 'heir': 23, 'bear': 24, 'memory': 25, 'thou': 26, 'contracted': 27, 'to': 28, 'thine': 29, 'own': 30, 'bright': 31, 'eyes': 32, 'feedst': 33, 'thy': 34, 'lights': 35, 'flame': 36, 'with': 37, 'selfsubstantial': 38, 'fuel': 39, 'making': 40, 'a': 41, 'famine': 42, 'where': 43, 'abundance': 44, 'lies': 45, 'self': 46, 'foe': 47, 'sweet': 48, 'too': 49, 'cruel': 50, 'art': 51, 'now': 52, 'worlds': 53, 'fresh': 54, 'ornament': 55, 'and': 56, 'only': 57, 'herald': 58, 'gaudy': 59, 'spring': 60, 'within': 61, 'bud': 62, 'buriest': 63, 'content': 64, 'churl': 65, 'makst': 66, 'waste': 67, 'in': 68, 'niggarding': 69, 'pity': 70, 'world': 71, 'or': 72, 'else': 73, 'this': 74, 'glutton': 75, 'be': 76, 'eat': 77, 'due': 78, 'grave': 79, 'thee': 80, 'when': 81, 'forty': 82, 'winters': 83, 'shall': 84, 'besiege': 85, 'brow': 86, 'dig': 87, 'deep': 88, 'trenches': 89, 'field': 90, 'youths': 91, 'proud': 92, 'livery': 93, 'so': 94, 'gazed': 95, 'on': 96, 'will': 97, 'tattered': 98, 'weed': 99, 'of': 100, 'small': 101, 'worth': 102, 'held': 103, 'then': 104, 'being': 105, 'asked': 106, 'all': 107, 'beauty': 108, 'treasure': 109, 'lusty': 110, 'days': 111, 'say': 112, 'sunken': 113, 'were': 114, 'an': 115, 'alleating': 116, 'shame': 117, 'thriftless': 118, 'praise': 119, 'how': 120, 'much': 121, 'more': 122, 'deserved': 123, 'use': 124, 'if': 125, 'couldst': 126, 'answer': 127, 'fair': 128, 'child': 129, 'mine': 130, 'sum': 131, 'my': 132, 'count': 133, 'make': 134, 'old': 135, 'excuse': 136, 'proving': 137, 'succession': 138, 'new': 139, 'made': 140, 'see': 141, 'blood': 142, 'warm': 143, 'feelst': 144, 'it': 145, 'cold': 146, 'look': 147, 'glass': 148, 'tell': 149, 'face': 150, 'viewest': 151, 'is': 152, 'form': 153, 'another': 154, 'whose': 155, 'repair': 156, 'not': 157, 'renewest': 158, 'dost': 159, 'beguile': 160, 'unbless': 161, 'some': 162, 'mother': 163, 'for': 164, 'she': 165, 'uneared': 166, 'womb': 167, 'disdains': 168, 'tillage': 169, 'husbandry': 170, 'who': 171, 'he': 172, 'fond': 173, 'tomb': 174, 'selflove': 175, 'stop': 176, 'posterity': 177, 'mothers': 178, 'calls': 179, 'back': 180, 'lovely': 181, 'april': 182, 'her': 183, 'prime': 184, 'through': 185, 'windows': 186, 'age': 187, 'shalt': 188, 'despite': 189, 'wrinkles': 190, 'golden': 191, 'live': 192, 'remembered': 193, 'single': 194, 'image': 195, 'dies': 196, 'unthrifty': 197, 'loveliness': 198, 'why': 199, 'spend': 200, 'upon': 201, 'legacy': 202, 'natures': 203, 'bequest': 204, 'gives': 205, 'nothing': 206, 'doth': 207, 'lend': 208, 'frank': 209, 'lends': 210, 'those': 211, 'are': 212, 'free': 213, 'beauteous': 214, 'niggard': 215, 'abuse': 216, 'bounteous': 217, 'largess': 218, 'given': 219, 'give': 220, 'profitless': 221, 'usurer': 222, 'great': 223, 'sums': 224, 'yet': 225, 'canst': 226, 'having': 227, 'traffic': 228, 'alone': 229, 'deceive': 230, 'nature': 231, 'gone': 232, 'what': 233, 'acceptable': 234, 'audit': 235, 'leave': 236, 'unused': 237, 'must': 238, 'tombed': 239, 'which': 240, 'used': 241, 'lives': 242, 'th': 243, 'executor': 244, 'hours': 245, 'gentle': 246, 'work': 247, 'did': 248, 'frame': 249, 'gaze': 250, 'every': 251, 'eye': 252, 'dwell': 253, 'play': 254, 'tyrants': 255, 'very': 256, 'same': 257, 'unfair': 258, 'fairly': 259, 'excel': 260, 'neverresting': 261, 'leads': 262, 'summer': 263, 'hideous': 264, 'winter': 265, 'confounds': 266, 'him': 267, 'there': 268, 'sap': 269, 'checked': 270, 'frost': 271, 'leaves': 272, 'quite': 273, 'oersnowed': 274, 'bareness': 275, 'summers': 276, 'distillation': 277, 'left': 278, 'liquid': 279, 'prisoner': 280, 'pent': 281, 'walls': 282, 'effect': 283, 'bereft': 284, 'nor': 285, 'no': 286, 'remembrance': 287, 'was': 288, 'flowers': 289, 'distilled': 290, 'though': 291, 'they': 292, 'meet': 293, 'leese': 294, 'their': 295, 'show': 296, 'substance': 297, 'still': 298, 'let': 299, 'ragged': 300, 'hand': 301, 'deface': 302, 'ere': 303, 'vial': 304, 'place': 305, 'selfkilled': 306, 'forbidden': 307, 'usury': 308, 'happies': 309, 'pay': 310, 'willing': 311, 'loan': 312, 'thats': 313, 'breed': 314, 'ten': 315, 'times': 316, 'happier': 317, 'one': 318, 'than': 319, 'refigured': 320, 'could': 321, 'death': 322, 'do': 323, 'shouldst': 324, 'depart': 325, 'leaving': 326, 'living': 327, 'selfwilled': 328, 'deaths': 329, 'conquest': 330, 'worms': 331, 'lo': 332, 'orient': 333, 'gracious': 334, 'light': 335, 'lifts': 336, 'up': 337, 'burning': 338, 'head': 339, 'each': 340, 'under': 341, 'homage': 342, 'newappearing': 343, 'sight': 344, 'serving': 345, 'looks': 346, 'sacred': 347, 'majesty': 348, 'climbed': 349, 'steepup': 350, 'heavenly': 351, 'hill': 352, 'resembling': 353, 'strong': 354, 'youth': 355, 'middle': 356, 'mortal': 357, 'adore': 358, 'attending': 359, 'pilgrimage': 360, 'highmost': 361, 'pitch': 362, 'weary': 363, 'car': 364, 'like': 365, 'feeble': 366, 'reeleth': 367, 'day': 368, '(fore': 369, 'duteous)': 370, 'converted': 371, 'low': 372, 'tract': 373, 'way': 374, 'outgoing': 375, 'noon': 376, 'unlooked': 377, 'diest': 378, 'unless': 379, 'get': 380, 'son': 381, 'music': 382, 'hear': 383, 'hearst': 384, 'sadly': 385, 'sweets': 386, 'war': 387, 'joy': 388, 'delights': 389, 'lovst': 390, 'receivst': 391, 'gladly': 392, 'pleasure': 393, 'annoy': 394, 'true': 395, 'concord': 396, 'welltuned': 397, 'sounds': 398, 'unions': 399, 'married': 400, 'offend': 401, 'ear': 402, 'sweetly': 403, 'chide': 404, 'singleness': 405, 'parts': 406, 'mark': 407, 'string': 408, 'husband': 409, 'strikes': 410, 'mutual': 411, 'ordering': 412, 'sire': 413, 'happy': 414, 'pleasing': 415, 'note': 416, 'sing': 417, 'speechless': 418, 'song': 419, 'many': 420, 'seeming': 421, 'sings': 422, 'wilt': 423, 'prove': 424, 'none': 425, 'fear': 426, 'wet': 427, 'widows': 428, 'consumst': 429, 'life': 430, 'ah': 431, 'issueless': 432, 'hap': 433, 'wail': 434, 'makeless': 435, 'wife': 436, 'widow': 437, 'weep': 438, 'hast': 439, 'behind': 440, 'private': 441, 'well': 442, 'may': 443, 'keep': 444, 'childrens': 445, 'husbands': 446, 'shape': 447, 'mind': 448, 'unthrift': 449, 'shifts': 450, 'enjoys': 451, 'hath': 452, 'end': 453, 'kept': 454, 'user': 455, 'destroys': 456, 'love': 457, 'toward': 458, 'others': 459, 'bosom': 460, 'sits': 461, 'himself': 462, 'such': 463, 'murdrous': 464, 'commits': 465, 'deny': 466, 'bearst': 467, 'any': 468, 'unprovident': 469, 'grant': 470, 'beloved': 471, 'most': 472, 'evident': 473, 'possessed': 474, 'hate': 475, 'gainst': 476, 'stickst': 477, 'conspire': 478, 'seeking': 479, 'roof': 480, 'ruinate': 481, 'chief': 482, 'o': 483, 'change': 484, 'thought': 485, 'i': 486, 'fairer': 487, 'lodged': 488, 'presence': 489, 'kind': 490, 'at': 491, 'least': 492, 'kindhearted': 493, 'me': 494, 'fast': 495, 'wane': 496, 'growst': 497, 'departest': 498, 'youngly': 499, 'bestowst': 500, 'mayst': 501, 'call': 502, 'convertest': 503, 'herein': 504, 'wisdom': 505, 'without': 506, 'folly': 507, 'decay': 508, 'minded': 509, 'cease': 510, 'threescore': 511, 'year': 512, 'would': 513, 'away': 514, 'whom': 515, 'store': 516, 'harsh': 517, 'featureless': 518, 'rude': 519, 'barrenly': 520, 'perish': 521, 'best': 522, 'endowed': 523, 'gave': 524, 'gift': 525, 'bounty': 526, 'cherish': 527, 'carved': 528, 'seal': 529, 'meant': 530, 'print': 531, 'copy': 532, 'clock': 533, 'tells': 534, 'brave': 535, 'sunk': 536, 'night': 537, 'behold': 538, 'violet': 539, 'past': 540, 'sable': 541, 'curls': 542, 'silvered': 543, 'oer': 544, 'white': 545, 'lofty': 546, 'trees': 547, 'barren': 548, 'erst': 549, 'heat': 550, 'canopy': 551, 'herd': 552, 'green': 553, 'girded': 554, 'sheaves': 555, 'borne': 556, 'bier': 557, 'bristly': 558, 'beard': 559, 'question': 560, 'among': 561, 'wastes': 562, 'go': 563, 'since': 564, 'beauties': 565, 'themselves': 566, 'forsake': 567, 'grow': 568, 'scythe': 569, 'can': 570, 'defence': 571, 'save': 572, 'takes': 573, 'hence': 574, 'you': 575, 'your': 576, 'longer': 577, 'yours': 578, 'here': 579, 'against': 580, 'coming': 581, 'prepare': 582, 'semblance': 583, 'other': 584, 'hold': 585, 'lease': 586, 'find': 587, 'determination': 588, 'again': 589, 'after': 590, 'selfs': 591, 'issue': 592, 'lets': 593, 'house': 594, 'fall': 595, 'honour': 596, 'uphold': 597, 'stormy': 598, 'gusts': 599, 'rage': 600, 'eternal': 601, 'unthrifts': 602, 'dear': 603, 'know': 604, 'had': 605, 'father': 606, 'stars': 607, 'judgement': 608, 'pluck': 609, 'methinks': 610, 'have': 611, 'astronomy': 612, 'good': 613, 'evil': 614, 'luck': 615, 'plagues': 616, 'dearths': 617, 'seasons': 618, 'quality': 619, 'fortune': 620, 'brief': 621, 'minutes': 622, 'pointing': 623, 'thunder': 624, 'rain': 625, 'wind': 626, 'princes': 627, 'oft': 628, 'predict': 629, 'heaven': 630, 'knowledge': 631, 'derive': 632, 'constant': 633, 'them': 634, 'read': 635, 'truth': 636, 'together': 637, 'thrive': 638, 'wouldst': 639, 'convert': 640, 'prognosticate': 641, 'truths': 642, 'doom': 643, 'date': 644, 'consider': 645, 'thing': 646, 'grows': 647, 'holds': 648, 'perfection': 649, 'little': 650, 'moment': 651, 'huge': 652, 'stage': 653, 'presenteth': 654, 'nought': 655, 'shows': 656, 'whereon': 657, 'secret': 658, 'influence': 659, 'comment': 660, 'perceive': 661, 'men': 662, 'plants': 663, 'cheered': 664, 'even': 665, 'selfsame': 666, 'sky': 667, 'vaunt': 668, 'youthful': 669, 'height': 670, 'decrease': 671, 'wear': 672, 'state': 673, 'out': 674, 'conceit': 675, 'inconstant': 676, 'stay': 677, 'sets': 678, 'rich': 679, 'before': 680, 'wasteful': 681, 'debateth': 682, 'sullied': 683, 'engraft': 684, 'wherefore': 685, 'mightier': 686, 'bloody': 687, 'tyrant': 688, 'fortify': 689, 'means': 690, 'blessed': 691, 'rhyme': 692, 'stand': 693, 'top': 694, 'maiden': 695, 'gardens': 696, 'unset': 697, 'virtuous': 698, 'wish': 699, 'liker': 700, 'painted': 701, 'counterfeit': 702, 'lines': 703, '(times': 704, 'pencil)': 705, 'pupil': 706, 'pen': 707, 'neither': 708, 'inward': 709, 'outward': 710, 'keeps': 711, 'drawn': 712, 'skill': 713, 'believe': 714, 'verse': 715, 'come': 716, 'filled': 717, 'high': 718, 'deserts': 719, 'knows': 720, 'hides': 721, 'half': 722, 'write': 723, 'numbers': 724, 'number': 725, 'graces': 726, 'poet': 727, 'touches': 728, 'neer': 729, 'touched': 730, 'earthly': 731, 'faces': 732, 'papers': 733, '(yellowed': 734, 'age)': 735, 'scorned': 736, 'less': 737, 'tongue': 738, 'rights': 739, 'termed': 740, 'poets': 741, 'stretched': 742, 'metre': 743, 'antique': 744, 'alive': 745, 'twice': 746, 'compare': 747, 'temperate': 748, 'rough': 749, 'winds': 750, 'shake': 751, 'darling': 752, 'buds': 753, 'short': 754, 'sometime': 755, 'hot': 756, 'shines': 757, 'often': 758, 'gold': 759, 'complexion': 760, 'dimmed': 761, 'declines': 762, 'chance': 763, 'changing': 764, 'course': 765, 'untrimmed': 766, 'fade': 767, 'lose': 768, 'possession': 769, 'owst': 770, 'brag': 771, 'wandrest': 772, 'shade': 773, 'long': 774, 'breathe': 775, 'devouring': 776, 'blunt': 777, 'lions': 778, 'paws': 779, 'earth': 780, 'devour': 781, 'brood': 782, 'keen': 783, 'teeth': 784, 'fierce': 785, 'tigers': 786, 'jaws': 787, 'burn': 788, 'longlived': 789, 'phoenix': 790, 'glad': 791, 'sorry': 792, 'fleetst': 793, 'whateer': 794, 'swiftfooted': 795, 'wide': 796, 'fading': 797, 'forbid': 798, 'heinous': 799, 'crime': 800, 'carve': 801, 'loves': 802, 'draw': 803, 'untainted': 804, 'allow': 805, 'pattern': 806, 'succeeding': 807, 'worst': 808, 'wrong': 809, 'ever': 810, 'young': 811, 'womans': 812, 'master': 813, 'mistress': 814, 'passion': 815, 'heart': 816, 'acquainted': 817, 'shifting': 818, 'false': 819, 'womens': 820, 'fashion': 821, 'theirs': 822, 'rolling': 823, 'gilding': 824, 'object': 825, 'whereupon': 826, 'gazeth': 827, 'man': 828, 'hue': 829, 'hues': 830, 'controlling': 831, 'steals': 832, 'mens': 833, 'souls': 834, 'amazeth': 835, 'woman': 836, 'wert': 837, 'first': 838, 'created': 839, 'till': 840, 'wrought': 841, 'fell': 842, 'adoting': 843, 'addition': 844, 'defeated': 845, 'adding': 846, 'purpose': 847, 'pricked': 848, 'muse': 849, 'stirred': 850, 'rehearse': 851, 'couplement': 852, 'sun': 853, 'moon': 854, 'seas': 855, 'gems': 856, 'aprils': 857, 'firstborn': 858, 'things': 859, 'rare': 860, 'heavens': 861, 'air': 862, 'rondure': 863, 'hems': 864, 'truly': 865, 'candles': 866, 'fixed': 867, 'hearsay': 868, 'sell': 869, 'persuade': 870, 'am': 871, 'furrows': 872, 'expiate': 873, 'cover': 874, 'seemly': 875, 'raiment': 876, 'breast': 877, 'elder': 878, 'therefore': 879, 'thyself': 880, 'wary': 881, 'bearing': 882, 'chary': 883, 'nurse': 884, 'babe': 885, 'faring': 886, 'ill': 887, 'presume': 888, 'slain': 889, 'gavst': 890, 'unperfect': 891, 'actor': 892, 'put': 893, 'beside': 894, 'part': 895, 'replete': 896, 'strengths': 897, 'weakens': 898, 'trust': 899, 'forget': 900, 'perfect': 901, 'ceremony': 902, 'rite': 903, 'strength': 904, 'seem': 905, 'oercharged': 906, 'burthen': 907, 'eloquence': 908, 'dumb': 909, 'presagers': 910, 'speaking': 911, 'plead': 912, 'recompense': 913, 'expressed': 914, 'learn': 915, 'silent': 916, 'writ': 917, 'belongs': 918, 'fine': 919, 'wit': 920, 'played': 921, 'painter': 922, 'stelled': 923, 'table': 924, 'body': 925, 'wherein': 926, 'tis': 927, 'perspective': 928, 'painters': 929, 'pictured': 930, 'bosoms': 931, 'shop': 932, 'hanging': 933, 'glazed': 934, 'turns': 935, 'done': 936, 'wherethrough': 937, 'peep': 938, 'therein': 939, 'cunning': 940, 'want': 941, 'grace': 942, 'favour': 943, 'public': 944, 'titles': 945, 'boast': 946, 'whilst': 947, 'triumph': 948, 'bars': 949, 'favourites': 950, 'spread': 951, 'marigold': 952, 'suns': 953, 'pride': 954, 'buried': 955, 'frown': 956, 'glory': 957, 'painful': 958, 'warrior': 959, 'famoused': 960, 'fight': 961, 'thousand': 962, 'victories': 963, 'once': 964, 'foiled': 965, 'book': 966, 'razed': 967, 'rest': 968, 'forgot': 969, 'toiled': 970, 'remove': 971, 'removed': 972, 'lord': 973, 'vassalage': 974, 'merit': 975, 'duty': 976, 'strongly': 977, 'knit': 978, 'send': 979, 'written': 980, 'embassage': 981, 'witness': 982, 'poor': 983, 'bare': 984, 'wanting': 985, 'words': 986, 'hope': 987, '(all': 988, 'naked)': 989, 'bestow': 990, 'whatsoever': 991, 'star': 992, 'guides': 993, 'moving': 994, 'points': 995, 'graciously': 996, 'aspect': 997, 'puts': 998, 'apparel': 999, 'loving': 1000, 'worthy': 1001, 'respect': 1002, 'dare': 1003, 'toil': 1004, 'haste': 1005, 'bed': 1006, 'respose': 1007, 'limbs': 1008, 'travel': 1009, 'tired': 1010, 'begins': 1011, 'journey': 1012, 'bodys': 1013, 'works': 1014, 'expired': 1015, 'thoughts': 1016, '(from': 1017, 'far': 1018, 'abide)': 1019, 'intend': 1020, 'zealous': 1021, 'drooping': 1022, 'eyelids': 1023, 'open': 1024, 'looking': 1025, 'darkness': 1026, 'blind': 1027, 'imaginary': 1028, 'presents': 1029, 'shadow': 1030, 'sightless': 1031, 'view': 1032, 'jewel': 1033, '(hung': 1034, 'ghastly': 1035, 'night)': 1036, 'makes': 1037, 'black': 1038, 'thus': 1039, 'quiet': 1040, 'return': 1041, 'plight': 1042, 'debarred': 1043, 'benefit': 1044, 'oppression': 1045, 'eased': 1046, 'oppressed': 1047, '(though': 1048, 'enemies': 1049, 'eithers': 1050, 'reign)': 1051, 'consent': 1052, 'hands': 1053, 'torture': 1054, 'complain': 1055, 'farther': 1056, 'off': 1057, 'please': 1058, 'clouds': 1059, 'blot': 1060, 'flatter': 1061, 'swartcomplexioned': 1062, 'sparkling': 1063, 'twire': 1064, 'gildst': 1065, 'daily': 1066, 'sorrows': 1067, 'nightly': 1068, 'griefs': 1069, 'length': 1070, 'stronger': 1071, 'disgrace': 1072, 'beweep': 1073, 'outcast': 1074, 'trouble': 1075, 'deaf': 1076, 'bootless': 1077, 'cries': 1078, 'curse': 1079, 'fate': 1080, 'wishing': 1081, 'featured': 1082, 'friends': 1083, 'desiring': 1084, 'mans': 1085, 'scope': 1086, 'enjoy': 1087, 'contented': 1088, 'these': 1089, 'almost': 1090, 'despising': 1091, 'haply': 1092, 'think': 1093, '(like': 1094, 'lark': 1095, 'break': 1096, 'arising': 1097, 'sullen': 1098, 'earth)': 1099, 'hymns': 1100, 'gate': 1101, 'wealth': 1102, 'brings': 1103, 'scorn': 1104, 'kings': 1105, 'sessions': 1106, 'summon': 1107, 'sigh': 1108, 'lack': 1109, 'sought': 1110, 'woes': 1111, 'drown': 1112, '(unused': 1113, 'flow)': 1114, 'precious': 1115, 'hid': 1116, 'dateless': 1117, 'afresh': 1118, 'cancelled': 1119, 'woe': 1120, 'moan': 1121, 'expense': 1122, 'vanished': 1123, 'grieve': 1124, 'grievances': 1125, 'foregone': 1126, 'heavily': 1127, 'sad': 1128, 'account': 1129, 'forebemoaned': 1130, 'paid': 1131, 'while': 1132, '(dear': 1133, 'friend)': 1134, 'losses': 1135, 'restored': 1136, 'endeared': 1137, 'hearts': 1138, 'lacking': 1139, 'supposed': 1140, 'dead': 1141, 'reigns': 1142, 'holy': 1143, 'obsequious': 1144, 'tear': 1145, 'religious': 1146, 'stoln': 1147, 'interest': 1148, 'appear': 1149, 'hidden': 1150, 'lie': 1151, 'hung': 1152, 'trophies': 1153, 'lovers': 1154, 'images': 1155, 'loved': 1156, 'they)': 1157, 'survive': 1158, 'wellcontented': 1159, 'bones': 1160, 'dust': 1161, 'resurvey': 1162, 'deceased': 1163, 'lover': 1164, 'bettring': 1165, 'outstripped': 1166, 'reserve': 1167, 'exceeded': 1168, 'vouchsafe': 1169, 'grown': 1170, 'growing': 1171, 'dearer': 1172, 'birth': 1173, 'brought': 1174, 'march': 1175, 'ranks': 1176, 'better': 1177, 'equipage': 1178, 'died': 1179, 'style': 1180, 'full': 1181, 'glorious': 1182, 'morning': 1183, 'seen': 1184, 'mountain': 1185, 'tops': 1186, 'sovereign': 1187, 'kissing': 1188, 'meadows': 1189, 'pale': 1190, 'streams': 1191, 'alchemy': 1192, 'anon': 1193, 'permit': 1194, 'basest': 1195, 'ride': 1196, 'ugly': 1197, 'rack': 1198, 'celestial': 1199, 'forlorn': 1200, 'visage': 1201, 'hide': 1202, 'stealing': 1203, 'unseen': 1204, 'west': 1205, 'early': 1206, 'morn': 1207, 'shine': 1208, 'triumphant': 1209, 'splendour': 1210, 'alack': 1211, 'hour': 1212, 'region': 1213, 'cloud': 1214, 'masked': 1215, 'whit': 1216, 'disdaineth': 1217, 'stain': 1218, 'staineth': 1219, 'didst': 1220, 'promise': 1221, 'forth': 1222, 'cloak': 1223, 'base': 1224, 'oertake': 1225, 'hiding': 1226, 'bravry': 1227, 'rotten': 1228, 'smoke': 1229, 'enough': 1230, 'dry': 1231, 'stormbeaten': 1232, 'salve': 1233, 'speak': 1234, 'heals': 1235, 'wound': 1236, 'cures': 1237, 'physic': 1238, 'grief': 1239, 'repent': 1240, 'loss': 1241, 'offenders': 1242, 'sorrow': 1243, 'weak': 1244, 'relief': 1245, 'bears': 1246, 'offences': 1247, 'cross': 1248, 'tears': 1249, 'pearl': 1250, 'sheds': 1251, 'ransom': 1252, 'deeds': 1253, 'grieved': 1254, 'roses': 1255, 'thorns': 1256, 'silver': 1257, 'fountains': 1258, 'mud': 1259, 'eclipses': 1260, 'both': 1261, 'loathsome': 1262, 'canker': 1263, 'sweetest': 1264, 'faults': 1265, 'authorizing': 1266, 'trespass': 1267, 'corrupting': 1268, 'salving': 1269, 'amiss': 1270, 'excusing': 1271, 'sins': 1272, 'sensual': 1273, 'fault': 1274, 'bring': 1275, 'sense': 1276, 'adverse': 1277, 'party': 1278, 'advocate': 1279, 'lawful': 1280, 'plea': 1281, 'commence': 1282, 'civil': 1283, 'accessary': 1284, 'needs': 1285, 'thief': 1286, 'sourly': 1287, 'robs': 1288, 'confess': 1289, 'two': 1290, 'twain': 1291, 'although': 1292, 'our': 1293, 'undivided': 1294, 'blots': 1295, 'remain': 1296, 'help': 1297, 'separable': 1298, 'spite': 1299, 'alter': 1300, 'sole': 1301, 'steal': 1302, 'delight': 1303, 'evermore': 1304, 'acknowledge': 1305, 'lest': 1306, 'bewailed': 1307, 'guilt': 1308, 'kindness': 1309, 'take': 1310, 'name': 1311, 'sort': 1312, 'report': 1313, 'decrepit': 1314, 'active': 1315, 'lame': 1316, 'fortunes': 1317, 'dearest': 1318, 'comfort': 1319, 'whether': 1320, 'entitled': 1321, 'crowned': 1322, 'sit': 1323, 'engrafted': 1324, 'despised': 1325, 'sufficed': 1326, 'subject': 1327, 'invent': 1328, 'pourst': 1329, 'into': 1330, 'argument': 1331, 'excellent': 1332, 'vulgar': 1333, 'paper': 1334, 'thanks': 1335, 'aught': 1336, 'perusal': 1337, 'whos': 1338, 'cannot': 1339, 'invention': 1340, 'tenth': 1341, 'nine': 1342, 'rhymers': 1343, 'invocate': 1344, 'outlive': 1345, 'slight': 1346, 'curious': 1347, 'pain': 1348, 'manners': 1349, 'ist': 1350, 'us': 1351, 'divided': 1352, 'separation': 1353, 'deservst': 1354, 'absence': 1355, 'torment': 1356, 'sour': 1357, 'leisure': 1358, 'entertain': 1359, 'teachest': 1360, 'praising': 1361, 'yea': 1362, 'hadst': 1363, 'receivest': 1364, 'blame': 1365, 'usest': 1366, 'blamed': 1367, 'deceivest': 1368, 'wilful': 1369, 'taste': 1370, 'refusest': 1371, 'forgive': 1372, 'robbery': 1373, 'poverty': 1374, 'greater': 1375, 'hates': 1376, 'known': 1377, 'injury': 1378, 'lascivious': 1379, 'kill': 1380, 'spites': 1381, 'foes': 1382, 'pretty': 1383, 'wrongs': 1384, 'liberty': 1385, 'absent': 1386, 'years': 1387, 'befits': 1388, 'temptation': 1389, 'follows': 1390, 'won': 1391, 'assailed': 1392, 'woos': 1393, 'prevailed': 1394, 'ay': 1395, 'mightst': 1396, 'seat': 1397, 'forbear': 1398, 'straying': 1399, 'lead': 1400, 'riot': 1401, 'forced': 1402, 'twofold': 1403, 'hers': 1404, 'tempting': 1405, 'said': 1406, 'dearly': 1407, 'wailing': 1408, 'nearly': 1409, 'ye': 1410, 'because': 1411, 'knowst': 1412, 'sake': 1413, 'suffring': 1414, 'friend': 1415, 'approve': 1416, 'gain': 1417, 'losing': 1418, 'found': 1419, 'lay': 1420, 'heres': 1421, 'flattery': 1422, 'wink': 1423, 'unrespected': 1424, 'sleep': 1425, 'dreams': 1426, 'darkly': 1427, 'dark': 1428, 'directed': 1429, 'shadows': 1430, 'clear': 1431, 'clearer': 1432, 'unseeing': 1433, '(i': 1434, 'say)': 1435, 'imperfect': 1436, 'heavy': 1437, 'nights': 1438, 'dull': 1439, 'flesh': 1440, 'injurious': 1441, 'distance': 1442, 'space': 1443, 'limits': 1444, 'remote': 1445, 'matter': 1446, 'foot': 1447, 'farthest': 1448, 'nimble': 1449, 'jump': 1450, 'sea': 1451, 'land': 1452, 'soon': 1453, 'kills': 1454, 'leap': 1455, 'large': 1456, 'lengths': 1457, 'miles': 1458, 'water': 1459, 'attend': 1460, 'receiving': 1461, 'elements': 1462, 'slow': 1463, 'badges': 1464, 'purging': 1465, 'fire': 1466, 'wherever': 1467, 'abide': 1468, 'presentabsent': 1469, 'swift': 1470, 'motion': 1471, 'slide': 1472, 'quicker': 1473, 'embassy': 1474, 'four': 1475, 'sinks': 1476, 'down': 1477, 'melancholy': 1478, 'until': 1479, 'lifes': 1480, 'composition': 1481, 'recured': 1482, 'messengers': 1483, 'returned': 1484, 'assured': 1485, 'health': 1486, 'recounting': 1487, 'told': 1488, 'straight': 1489, 'divide': 1490, 'pictures': 1491, 'bar': 1492, 'freedom': 1493, 'right': 1494, '(a': 1495, 'closet': 1496, 'pierced': 1497, 'crystal': 1498, 'eyes)': 1499, 'defendant': 1500, 'says': 1501, 'appearance': 1502, 'side': 1503, 'title': 1504, 'impanelled': 1505, 'quest': 1506, 'tenants': 1507, 'verdict': 1508, 'determined': 1509, 'moiety': 1510, 'betwixt': 1511, 'league': 1512, 'took': 1513, 'unto': 1514, 'famished': 1515, 'sighs': 1516, 'smother': 1517, 'picture': 1518, 'feast': 1519, 'banquet': 1520, 'bids': 1521, 'guest': 1522, 'share': 1523, 'either': 1524, 'present': 1525, 'move': 1526, 'awakes': 1527, 'careful': 1528, 'trifle': 1529, 'truest': 1530, 'thrust': 1531, 'falsehood': 1532, 'sure': 1533, 'wards': 1534, 'jewels': 1535, 'trifles': 1536, 'greatest': 1537, 'care': 1538, 'prey': 1539, 'locked': 1540, 'chest': 1541, 'feel': 1542, 'closure': 1543, 'whence': 1544, 'thence': 1545, 'proves': 1546, 'thievish': 1547, 'prize': 1548, '(if': 1549, 'come)': 1550, 'defects': 1551, 'cast': 1552, 'utmost': 1553, 'called': 1554, 'advised': 1555, 'respects': 1556, 'strangely': 1557, 'pass': 1558, 'scarcely': 1559, 'greet': 1560, 'reasons': 1561, 'settled': 1562, 'gravity': 1563, 'ensconce': 1564, 'desert': 1565, 'uprear': 1566, 'guard': 1567, 'laws': 1568, 'allege': 1569, 'cause': 1570, 'seek': 1571, '(my': 1572, 'travels': 1573, 'end)': 1574, 'teach': 1575, 'case': 1576, 'repose': 1577, 'measured': 1578, 'beast': 1579, 'plods': 1580, 'dully': 1581, 'weight': 1582, 'instinct': 1583, 'wretch': 1584, 'rider': 1585, 'speed': 1586, 'spur': 1587, 'provoke': 1588, 'sometimes': 1589, 'anger': 1590, 'thrusts': 1591, 'answers': 1592, 'groan': 1593, 'sharp': 1594, 'spurring': 1595, 'onward': 1596, 'offence': 1597, 'bearer': 1598, 'posting': 1599, 'need': 1600, 'extremity': 1601, 'mounted': 1602, 'winged': 1603, 'horse': 1604, 'pace': 1605, '(of': 1606, 'perfectst': 1607, 'made)': 1608, 'neigh': 1609, '(no': 1610, 'flesh)': 1611, 'fiery': 1612, 'race': 1613, 'jade': 1614, 'going': 1615, 'went': 1616, 'wilfulslow': 1617, 'towards': 1618, 'run': 1619, 'key': 1620, 'uplocked': 1621, 'survey': 1622, 'blunting': 1623, 'point': 1624, 'seldom': 1625, 'feasts': 1626, 'solemn': 1627, 'set': 1628, 'stones': 1629, 'thinly': 1630, 'placed': 1631, 'captain': 1632, 'carcanet': 1633, 'wardrobe': 1634, 'robe': 1635, 'special': 1636, 'instant': 1637, 'specialblest': 1638, 'unfolding': 1639, 'imprisoned': 1640, 'worthiness': 1641, 'lacked': 1642, 'whereof': 1643, 'millions': 1644, 'strange': 1645, 'tend': 1646, 'describe': 1647, 'adonis': 1648, 'poorly': 1649, 'imitated': 1650, 'helens': 1651, 'cheek': 1652, 'grecian': 1653, 'tires': 1654, 'foison': 1655, 'external': 1656, 'deem': 1657, 'odour': 1658, 'blooms': 1659, 'dye': 1660, 'perfumed': 1661, 'tincture': 1662, 'hang': 1663, 'wantonly': 1664, 'breath': 1665, 'discloses': 1666, 'virtue': 1667, 'unwooed': 1668, 'odours': 1669, 'distills': 1670, 'marble': 1671, 'gilded': 1672, 'monuments': 1673, 'powerful': 1674, 'contents': 1675, 'unswept': 1676, 'stone': 1677, 'besmeared': 1678, 'sluttish': 1679, 'statues': 1680, 'overturn': 1681, 'broils': 1682, 'root': 1683, 'masonry': 1684, 'mars': 1685, 'sword': 1686, 'wars': 1687, 'quick': 1688, 'record': 1689, 'alloblivious': 1690, 'enmity': 1691, 'room': 1692, 'ending': 1693, 'judgment': 1694, 'arise': 1695, 'renew': 1696, 'force': 1697, 'edge': 1698, 'blunter': 1699, 'appetite': 1700, 'today': 1701, 'feeding': 1702, 'allayed': 1703, 'tomorrow': 1704, 'sharpened': 1705, 'former': 1706, 'fill': 1707, 'hungry': 1708, 'fulness': 1709, 'spirit': 1710, 'perpetual': 1711, 'dulness': 1712, 'interim': 1713, 'ocean': 1714, 'shore': 1715, 'banks': 1716, 'blest': 1717, 'welcome': 1718, 'thrice': 1719, 'wished': 1720, 'slave': 1721, 'services': 1722, 'require': 1723, 'worldwithoutend': 1724, 'sovereign)': 1725, 'watch': 1726, 'bitterness': 1727, 'bid': 1728, 'servant': 1729, 'adieu': 1730, 'jealous': 1731, 'affairs': 1732, 'suppose': 1733, 'fool': 1734, 'thing)': 1735, 'thinks': 1736, 'god': 1737, 'control': 1738, 'crave': 1739, 'vassal': 1740, 'bound': 1741, 'suffer': 1742, '(being': 1743, 'beck)': 1744, 'patience': 1745, 'tame': 1746, 'sufferance': 1747, 'bide': 1748, 'check': 1749, 'accusing': 1750, 'list': 1751, 'charter': 1752, 'privilage': 1753, 'belong': 1754, 'pardon': 1755, 'selfdoing': 1756, 'wait': 1757, 'waiting': 1758, 'hell': 1759, 'been': 1760, 'brains': 1761, 'beguiled': 1762, 'labouring': 1763, 'amis': 1764, 'second': 1765, 'backward': 1766, 'five': 1767, 'hundred': 1768, 'courses': 1769, 'character': 1770, 'composed': 1771, 'wonder': 1772, 'mended': 1773, 'revolution': 1774, 'wits': 1775, 'subjects': 1776, 'worse': 1777, 'admiring': 1778, 'waves': 1779, 'pebbled': 1780, 'hasten': 1781, 'goes': 1782, 'sequent': 1783, 'forwards': 1784, 'contend': 1785, 'nativity': 1786, 'main': 1787, 'crawls': 1788, 'maturity': 1789, 'wherewith': 1790, 'crooked': 1791, 'confound': 1792, 'transfix': 1793, 'flourish': 1794, 'delves': 1795, 'parallels': 1796, 'feeds': 1797, 'rarities': 1798, 'stands': 1799, 'mow': 1800, 'slumbers': 1801, 'broken': 1802, 'mock': 1803, 'sendst': 1804, 'home': 1805, 'pry': 1806, 'shames': 1807, 'idle': 1808, 'tenure': 1809, 'jealousy': 1810, 'awake': 1811, 'defeat': 1812, 'watchman': 1813, 'wake': 1814, 'elsewhere': 1815, 'near': 1816, 'sin': 1817, 'possesseth': 1818, 'soul': 1819, 'remedy': 1820, 'grounded': 1821, 'define': 1822, 'worths': 1823, 'surmount': 1824, 'indeed': 1825, 'beated': 1826, 'chopt': 1827, 'tanned': 1828, 'antiquity': 1829, 'contrary': 1830, 'selfloving': 1831, 'iniquity': 1832, 'self)': 1833, 'painting': 1834, 'crushed': 1835, 'oerworn': 1836, 'drained': 1837, 'travelled': 1838, 'ages': 1839, 'steepy': 1840, 'hes': 1841, 'king': 1842, 'vanishing': 1843, 'confounding': 1844, 'knife': 1845, 'cut': 1846, 'defaced': 1847, 'richproud': 1848, 'cost': 1849, 'outworn': 1850, 'towers': 1851, 'downrased': 1852, 'brass': 1853, 'advantage': 1854, 'kingdom': 1855, 'firm': 1856, 'soil': 1857, 'win': 1858, 'watery': 1859, 'increasing': 1860, 'interchange': 1861, 'confounded': 1862, 'ruin': 1863, 'taught': 1864, 'ruminate': 1865, 'choose': 1866, 'fears': 1867, 'boundless': 1868, 'mortality': 1869, 'oersways': 1870, 'power': 1871, 'action': 1872, 'flower': 1873, 'honey': 1874, 'wrackful': 1875, 'siege': 1876, 'battring': 1877, 'rocks': 1878, 'impregnable': 1879, 'stout': 1880, 'gates': 1881, 'steel': 1882, 'decays': 1883, 'fearful': 1884, 'meditation': 1885, 'spoil': 1886, 'miracle': 1887, 'ink': 1888, 'restful': 1889, 'cry': 1890, 'beggar': 1891, 'born': 1892, 'needy': 1893, 'trimmed': 1894, 'jollity': 1895, 'purest': 1896, 'faith': 1897, 'unhappily': 1898, 'forsworn': 1899, 'shamefully': 1900, 'misplaced': 1901, 'rudely': 1902, 'strumpeted': 1903, 'wrongfully': 1904, 'disgraced': 1905, 'limping': 1906, 'sway': 1907, 'disabled': 1908, 'tonguetied': 1909, 'authority': 1910, '(doctorlike)': 1911, 'simple': 1912, 'miscalled': 1913, 'simplicity': 1914, 'captive': 1915, 'infection': 1916, 'impiety': 1917, 'achieve': 1918, 'lace': 1919, 'society': 1920, 'imitate': 1921, 'indirectly': 1922, 'bankrupt': 1923, 'beggared': 1924, 'blush': 1925, 'lively': 1926, 'veins': 1927, 'exchequer': 1928, 'gains': 1929, 'stores': 1930, 'last': 1931, 'bad': 1932, 'map': 1933, 'lived': 1934, 'bastard': 1935, 'signs': 1936, 'durst': 1937, 'inhabit': 1938, 'tresses': 1939, 'sepulchres': 1940, 'shorn': 1941, 'fleece': 1942, 'gay': 1943, 'anothers': 1944, 'robbing': 1945, 'dress': 1946, 'yore': 1947, 'mend': 1948, 'tongues': 1949, '(the': 1950, 'voice': 1951, 'souls)': 1952, 'uttering': 1953, 'commend': 1954, 'accents': 1955, 'seeing': 1956, 'shown': 1957, 'guess': 1958, 'measure': 1959, 'churls': 1960, '(although': 1961, 'kind)': 1962, 'add': 1963, 'rank': 1964, 'smell': 1965, 'weeds': 1966, 'matcheth': 1967, 'common': 1968, 'defect': 1969, 'slanders': 1970, 'suspect': 1971, 'crow': 1972, 'flies': 1973, 'slander': 1974, 'wooed': 1975, 'vice': 1976, 'presentst': 1977, 'pure': 1978, 'unstained': 1979, 'passed': 1980, 'ambush': 1981, 'victor': 1982, 'charged': 1983, 'tie': 1984, 'envy': 1985, 'enlarged': 1986, 'kingdoms': 1987, 'owe': 1988, 'mourn': 1989, 'surly': 1990, 'bell': 1991, 'warning': 1992, 'fled': 1993, 'vile': 1994, 'vilest': 1995, 'nay': 1996, 'line': 1997, 'remember': 1998, 'thinking': 1999, '(perhaps)': 2000, 'compounded': 2001, 'clay': 2002, 'wise': 2003, 'task': 2004, 'recite': 2005, 'love)': 2006, 'devise': 2007, 'willingly': 2008, 'impart': 2009, 'untrue': 2010, 'shamed': 2011, 'yellow': 2012, 'few': 2013, 'boughs': 2014, 'ruined': 2015, 'choirs': 2016, 'late': 2017, 'birds': 2018, 'sang': 2019, 'seest': 2020, 'twilight': 2021, 'sunset': 2022, 'fadeth': 2023, 'seals': 2024, 'glowing': 2025, 'ashes': 2026, 'deathbed': 2027, 'expire': 2028, 'consumed': 2029, 'nourished': 2030, 'perceivst': 2031, 'arrest': 2032, 'bail': 2033, 'carry': 2034, 'memorial': 2035, 'reviewest': 2036, 'review': 2037, 'consecrate': 2038, 'lost': 2039, 'dregs': 2040, 'coward': 2041, 'wretchs': 2042, 'contains': 2043, 'remains': 2044, 'food': 2045, 'sweetseasoned': 2046, 'showers': 2047, 'ground': 2048, 'peace': 2049, 'strife': 2050, 'twixt': 2051, 'miser': 2052, 'enjoyer': 2053, 'doubting': 2054, 'filching': 2055, 'counting': 2056, 'bettered': 2057, 'feasting': 2058, 'clean': 2059, 'starved': 2060, 'possessing': 2061, 'pursuing': 2062, 'pine': 2063, 'surfeit': 2064, 'gluttoning': 2065, 'variation': 2066, 'glance': 2067, 'aside': 2068, 'newfound': 2069, 'methods': 2070, 'compounds': 2071, 'noted': 2072, 'word': 2073, 'showing': 2074, 'proceed': 2075, 'always': 2076, 'dressing': 2077, 'spending': 2078, 'already': 2079, 'spent': 2080, 'telling': 2081, 'dial': 2082, 'vacant': 2083, 'minds': 2084, 'imprint': 2085, 'learning': 2086, 'mouthed': 2087, 'graves': 2088, 'dials': 2089, 'shady': 2090, 'stealth': 2091, 'progress': 2092, 'eternity': 2093, 'contain': 2094, 'commit': 2095, 'blanks': 2096, 'children': 2097, 'nursed': 2098, 'delivered': 2099, 'brain': 2100, 'acquaintance': 2101, 'offices': 2102, 'profit': 2103, 'enrich': 2104, 'invoked': 2105, 'assistance': 2106, 'alien': 2107, 'got': 2108, 'poesy': 2109, 'disperse': 2110, 'ignorance': 2111, 'aloft': 2112, 'fly': 2113, 'added': 2114, 'feathers': 2115, 'learneds': 2116, 'wing': 2117, 'double': 2118, 'compile': 2119, 'arts': 2120, 'graced': 2121, 'advance': 2122, 'aid': 2123, 'decayed': 2124, 'sick': 2125, '(sweet': 2126, 'deserves': 2127, 'travail': 2128, 'worthier': 2129, 'pays': 2130, 'stole': 2131, 'behaviour': 2132, 'afford': 2133, 'thank': 2134, 'owes': 2135, 'faint': 2136, 'knowing': 2137, 'thereof': 2138, 'spends': 2139, 'fame': 2140, '(wide': 2141, 'is)': 2142, 'humble': 2143, 'proudest': 2144, 'sail': 2145, 'saucy': 2146, 'bark': 2147, '(inferior': 2148, 'his)': 2149, 'broad': 2150, 'wilfully': 2151, 'shallowest': 2152, 'afloat': 2153, 'soundless': 2154, 'wrecked)': 2155, 'worthless': 2156, 'boat': 2157, 'tall': 2158, 'building': 2159, 'goodly': 2160, 'epitaph': 2161, 'forgotten': 2162, 'immortal': 2163, '(once': 2164, 'gone)': 2165, 'yield': 2166, 'entombed': 2167, 'monument': 2168, 'oerread': 2169, 'breathers': 2170, '(such': 2171, 'pen)': 2172, 'breathes': 2173, 'mouths': 2174, 'attaint': 2175, 'oerlook': 2176, 'dedicated': 2177, 'writers': 2178, 'blessing': 2179, 'finding': 2180, 'limit': 2181, 'enforced': 2182, 'anew': 2183, 'fresher': 2184, 'stamp': 2185, 'timebettering': 2186, 'devised': 2187, 'strained': 2188, 'rhetoric': 2189, 'sympathized': 2190, 'plain': 2191, 'truetelling': 2192, 'gross': 2193, 'cheeks': 2194, 'abused': 2195, 'saw': 2196, '(or': 2197, 'found)': 2198, 'exceed': 2199, 'debt': 2200, 'slept': 2201, 'extant': 2202, 'modern': 2203, 'quill': 2204, 'silence': 2205, 'impute': 2206, 'impair': 2207, 'mute': 2208, 'confine': 2209, 'immured': 2210, 'example': 2211, 'equal': 2212, 'grew': 2213, 'lean': 2214, 'penury': 2215, 'writes': 2216, 'dignifies': 2217, 'story': 2218, 'counterpart': 2219, 'admired': 2220, 'blessings': 2221, 'praises': 2222, 'comments': 2223, 'richly': 2224, 'compiled': 2225, 'phrase': 2226, 'muses': 2227, 'filed': 2228, 'unlettered': 2229, 'clerk': 2230, 'amen': 2231, 'hymn': 2232, 'able': 2233, 'affords': 2234, 'polished': 2235, 'refined': 2236, 'hearing': 2237, 'praised': 2238, 'something': 2239, 'hindmost)': 2240, 'precious)': 2241, 'ripe': 2242, 'inhearse': 2243, 'spirits': 2244, 'above': 2245, 'struck': 2246, 'compeers': 2247, 'giving': 2248, 'astonished': 2249, 'affable': 2250, 'familiar': 2251, 'ghost': 2252, 'gulls': 2253, 'intelligence': 2254, 'victors': 2255, 'countenance': 2256, 'enfeebled': 2257, 'farewell': 2258, 'estimate': 2259, 'releasing': 2260, 'bonds': 2261, 'determinate': 2262, 'granting': 2263, 'riches': 2264, 'deserving': 2265, 'patent': 2266, 'swerving': 2267, 'mistaking': 2268, 'misprision': 2269, 'comes': 2270, 'dream': 2271, 'waking': 2272, 'disposed': 2273, 'weakness': 2274, 'concealed': 2275, 'attainted': 2276, 'gainer': 2277, 'bending': 2278, 'injuries': 2279, 'doing': 2280, 'vantage': 2281, 'doublevantage': 2282, 'lameness': 2283, 'halt': 2284, '(love)': 2285, 'desired': 2286, 'strangle': 2287, 'walks': 2288, '(too': 2289, 'profane)': 2290, 'wronk': 2291, 'vow': 2292, 'debate': 2293, 'bent': 2294, 'join': 2295, 'bow': 2296, 'drop': 2297, 'afterloss': 2298, 'scaped': 2299, 'rearward': 2300, 'conquered': 2301, 'windy': 2302, 'rainy': 2303, 'morrow': 2304, 'linger': 2305, 'purposed': 2306, 'overthrow': 2307, 'petty': 2308, 'onset': 2309, 'strains': 2310, 'compared': 2311, 'garments': 2312, 'newfangled': 2313, 'hawks': 2314, 'hounds': 2315, 'humour': 2316, 'adjunct': 2317, 'finds': 2318, 'particulars': 2319, 'general': 2320, 'richer': 2321, 'prouder': 2322, 'costs': 2323, 'horses': 2324, 'wretched': 2325, 'term': 2326, 'depends': 2327, 'depend': 2328, 'vex': 2329, 'revolt': 2330, 'whats': 2331, 'blessedfair': 2332, 'supposing': 2333, 'deceived': 2334, 'altered': 2335, 'hatred': 2336, 'manys': 2337, 'history': 2338, 'moods': 2339, 'frowns': 2340, 'creation': 2341, 'decree': 2342, 'workings': 2343, 'sweetness': 2344, 'eves': 2345, 'apple': 2346, 'hurt': 2347, 'unmoved': 2348, 'rightly': 2349, 'inherit': 2350, 'tibey': 2351, 'lords': 2352, 'owners': 2353, 'stewards': 2354, 'excellence': 2355, 'outbraves': 2356, 'dignity': 2357, 'turn': 2358, 'sourest': 2359, 'lilies': 2360, 'fester': 2361, 'fragrant': 2362, 'spot': 2363, 'budding': 2364, 'enclose': 2365, '(making': 2366, 'sport)': 2367, 'dispraise': 2368, 'naming': 2369, 'blesses': 2370, 'mansion': 2371, 'vices': 2372, 'habitation': 2373, 'chose': 2374, 'veil': 2375, 'heed': 2376, 'heart)': 2377, 'privilege': 2378, 'hardest': 2379, 'illused': 2380, 'wantonness': 2381, 'sport': 2382, 'resort': 2383, 'finger': 2384, 'throned': 2385, 'queen': 2386, 'esteemed': 2387, 'errors': 2388, 'translated': 2389, 'deemed': 2390, 'lambs': 2391, 'stern': 2392, 'wolf': 2393, 'betray': 2394, 'lamb': 2395, 'translate': 2396, 'gazers': 2397, 'fleeting': 2398, 'freezings': 2399, 'felt': 2400, 'decembers': 2401, 'everywhere': 2402, 'teeming': 2403, 'autumn': 2404, 'big': 2405, 'wanton': 2406, 'burden': 2407, 'widowed': 2408, 'wombs': 2409, 'abundant': 2410, 'seemed': 2411, 'orphans': 2412, 'unfathered': 2413, 'fruit': 2414, 'pleasures': 2415, 'cheer': 2416, 'dreading': 2417, 'proudpied': 2418, '(dressed': 2419, 'trim)': 2420, 'saturn': 2421, 'laughed': 2422, 'leaped': 2423, 'lays': 2424, 'different': 2425, 'lap': 2426, 'lilys': 2427, 'vermilion': 2428, 'figures': 2429, 'forgetst': 2430, 'spendst': 2431, 'fury': 2432, 'darkening': 2433, 'forgetful': 2434, 'redeem': 2435, 'idly': 2436, 'esteem': 2437, 'rise': 2438, 'resty': 2439, 'wrinkle': 2440, 'graven': 2441, 'satire': 2442, 'spoils': 2443, 'faster': 2444, 'preventst': 2445, 'truant': 2446, 'amends': 2447, 'neglect': 2448, 'dyed': 2449, 'dignified': 2450, 'colour': 2451, 'pencil': 2452, 'intermixed': 2453, 'fort': 2454, 'office': 2455, 'strengthened': 2456, 'merchandized': 2457, 'esteeming': 2458, 'publish': 2459, 'wont': 2460, 'philomel': 2461, 'front': 2462, 'stops': 2463, 'pipe': 2464, 'growth': 2465, 'pleasant': 2466, 'mournful': 2467, 'hush': 2468, 'wild': 2469, 'burthens': 2470, 'bough': 2471, 'appears': 2472, 'overgoes': 2473, 'dulling': 2474, 'sinful': 2475, 'striving': 2476, 'mar': 2477, 'verses': 2478, 'gifts': 2479, 'eyed': 2480, 'seems': 2481, 'three': 2482, 'forests': 2483, 'shook': 2484, 'springs': 2485, 'turned': 2486, 'process': 2487, 'perfumes': 2488, 'junes': 2489, 'burned': 2490, 'figure': 2491, 'perceived': 2492, 'unbred': 2493, 'idolatry': 2494, 'idol': 2495, 'alike': 2496, 'songs': 2497, 'wondrous': 2498, 'constancy': 2499, 'confined': 2500, 'expressing': 2501, 'difference': 2502, 'varying': 2503, 'themes': 2504, 'chronicle': 2505, 'wasted': 2506, 'descriptions': 2507, 'wights': 2508, 'beautiful': 2509, 'ladies': 2510, 'knights': 2511, 'blazon': 2512, 'lip': 2513, 'prophecies': 2514, 'prefiguring': 2515, 'looked': 2516, 'divining': 2517, 'prophetic': 2518, 'dreaming': 2519, 'forfeit': 2520, 'eclipse': 2521, 'endured': 2522, 'augurs': 2523, 'presage': 2524, 'incertainties': 2525, 'crown': 2526, 'proclaims': 2527, 'olives': 2528, 'endless': 2529, 'drops': 2530, 'balmy': 2531, 'subscribes': 2532, 'insults': 2533, 'tribes': 2534, 'crests': 2535, 'tombs': 2536, 'figured': 2537, 'register': 2538, 'express': 2539, 'boy': 2540, 'prayers': 2541, 'divine': 2542, 'hallowed': 2543, 'weighs': 2544, 'necessary': 2545, 'aye': 2546, 'page': 2547, 'bred': 2548, 'qualify': 2549, 'easy': 2550, 'ranged': 2551, 'just': 2552, 'exchanged': 2553, 'reigned': 2554, 'frailties': 2555, 'kinds': 2556, 'preposterously': 2557, 'stained': 2558, 'universe': 2559, 'alas': 2560, 'motley': 2561, 'gored': 2562, 'sold': 2563, 'cheap': 2564, 'affections': 2565, 'askance': 2566, 'blenches': 2567, 'essays': 2568, 'proved': 2569, 'grind': 2570, 'newer': 2571, 'proof': 2572, 'try': 2573, 'older': 2574, 'next': 2575, 'guilty': 2576, 'goddess': 2577, 'harmful': 2578, 'provide': 2579, 'breeds': 2580, 'receives': 2581, 'brand': 2582, 'subdued': 2583, 'dyers': 2584, 'renewed': 2585, 'patient': 2586, 'drink': 2587, 'potions': 2588, 'eisel': 2589, 'bitter': 2590, 'penance': 2591, 'correct': 2592, 'correction': 2593, 'assure': 2594, 'cure': 2595, 'impression': 2596, 'scandal': 2597, 'stamped': 2598, 'oergreen': 2599, 'strive': 2600, 'steeled': 2601, 'changes': 2602, 'profound': 2603, 'abysm': 2604, 'throw': 2605, 'voices': 2606, 'adders': 2607, 'critic': 2608, 'flatterer': 2609, 'stopped': 2610, 'dispense': 2611, 'besides': 2612, 'governs': 2613, 'about': 2614, 'function': 2615, 'partly': 2616, 'effectually': 2617, 'delivers': 2618, 'bird': 2619, 'latch': 2620, 'objects': 2621, 'vision': 2622, 'catch': 2623, 'rudst': 2624, 'gentlest': 2625, 'deformedst': 2626, 'creature': 2627, 'dove': 2628, 'shapes': 2629, 'feature': 2630, 'incapable': 2631, 'maketh': 2632, 'monarchs': 2633, 'plague': 2634, 'saith': 2635, 'monsters': 2636, 'indigest': 2637, 'cherubins': 2638, 'resemble': 2639, 'creating': 2640, 'beams': 2641, 'assemble': 2642, 'kingly': 2643, 'drinks': 2644, 'gust': 2645, 'greeing': 2646, 'palate': 2647, 'cup': 2648, 'poisoned': 2649, 'lesser': 2650, 'begin': 2651, 'knew': 2652, 'reason': 2653, 'afterwards': 2654, 'reckoning': 2655, 'millioned': 2656, 'accidents': 2657, 'creep': 2658, 'vows': 2659, 'decrees': 2660, 'tan': 2661, 'sharpst': 2662, 'intents': 2663, 'divert': 2664, 'altring': 2665, 'fearing': 2666, 'tyranny': 2667, 'certain': 2668, 'incertainty': 2669, 'crowning': 2670, 'marriage': 2671, 'admit': 2672, 'impediments': 2673, 'alters': 2674, 'alteration': 2675, 'bends': 2676, 'remover': 2677, 'everfixed': 2678, 'tempests': 2679, 'shaken': 2680, 'wandring': 2681, 'unknown': 2682, 'taken': 2683, 'rosy': 2684, 'lips': 2685, 'sickles': 2686, 'compass': 2687, 'weeks': 2688, 'error': 2689, 'accuse': 2690, 'scanted': 2691, 'repay': 2692, 'whereto': 2693, 'frequent': 2694, 'dearpurchased': 2695, 'hoisted': 2696, 'transport': 2697, 'wilfulness': 2698, 'surmise': 2699, 'accumulate': 2700, 'level': 2701, 'shoot': 2702, 'wakened': 2703, 'appeal': 2704, 'eager': 2705, 'urge': 2706, 'prevent': 2707, 'maladies': 2708, 'sicken': 2709, 'shun': 2710, 'sickness': 2711, 'purge': 2712, 'neercloying': 2713, 'sauces': 2714, 'welfare': 2715, 'meetness': 2716, 'diseased': 2717, 'needing': 2718, 'policy': 2719, 't': 2720, 'anticipate': 2721, 'ills': 2722, 'medicine': 2723, 'healthful': 2724, 'goodness': 2725, 'cured': 2726, 'lesson': 2727, 'drugs': 2728, 'poison': 2729, 'feil': 2730, 'drunk': 2731, 'siren': 2732, 'limbecks': 2733, 'foul': 2734, 'applying': 2735, 'hopes': 2736, 'committed': 2737, 'spheres': 2738, 'fitted': 2739, 'distraction': 2740, 'madding': 2741, 'fever': 2742, 'built': 2743, 'rebuked': 2744, 'unkind': 2745, 'befriends': 2746, 'transgression': 2747, 'nerves': 2748, 'hammered': 2749, 'unkindness': 2750, 'yhave': 2751, 'weigh': 2752, 'suffered': 2753, 'deepest': 2754, 'hard': 2755, 'hits': 2756, 'tendered': 2757, 'wounded': 2758, 'fits': 2759, 'becomes': 2760, 'fee': 2761, 'ransoms': 2762, 'reproach': 2763, 'feeling': 2764, 'adulterate': 2765, 'salutation': 2766, 'sportive': 2767, 'frailer': 2768, 'spies': 2769, 'wills': 2770, 'abuses': 2771, 'reckon': 2772, 'bevel': 2773, 'maintain': 2774, 'badness': 2775, 'reign': 2776, 'tables': 2777, 'charactered': 2778, 'lasting': 2779, 'beyond': 2780, 'faculty': 2781, 'subsist': 2782, 'oblivion': 2783, 'missed': 2784, 'retention': 2785, 'tallies': 2786, 'score': 2787, 'bold': 2788, 'receive': 2789, 'import': 2790, 'forgetfulness': 2791, 'pyramids': 2792, 'novel': 2793, 'dressings': 2794, 'dates': 2795, 'admire': 2796, 'foist': 2797, 'rather': 2798, 'heard': 2799, 'registers': 2800, 'defy': 2801, 'wondring': 2802, 'records': 2803, 'continual': 2804, 'gathered': 2805, 'builded': 2806, 'accident': 2807, 'suffers': 2808, 'smiling': 2809, 'pomp': 2810, 'falls': 2811, 'blow': 2812, 'thralled': 2813, 'discontent': 2814, 'inviting': 2815, 'heretic': 2816, 'leases': 2817, 'shortnumbered': 2818, 'hugely': 2819, 'politic': 2820, 'drowns': 2821, 'fools': 2822, 'weret': 2823, 'bore': 2824, 'extern': 2825, 'honouring': 2826, 'laid': 2827, 'bases': 2828, 'ruining': 2829, 'dwellers': 2830, 'paying': 2831, 'rent': 2832, 'compound': 2833, 'forgoing': 2834, 'savour': 2835, 'pitiful': 2836, 'thrivers': 2837, 'gazing': 2838, 'oblation': 2839, 'mixed': 2840, 'seconds': 2841, 'render': 2842, 'suborned': 2843, 'informer': 2844, 'impeached': 2845, 'counted': 2846, 'successive': 2847, 'slandered': 2848, 'fairing': 2849, 'borrowed': 2850, 'bower': 2851, 'profaned': 2852, 'raven': 2853, 'suited': 2854, 'mourners': 2855, 'slandering': 2856, 'becoming': 2857, 'playst': 2858, 'wood': 2859, 'fingers': 2860, 'gently': 2861, 'swayst': 2862, 'wiry': 2863, 'jacks': 2864, 'kiss': 2865, 'harvest': 2866, 'reap': 2867, 'woods': 2868, 'boldness': 2869, 'blushing': 2870, 'tickled': 2871, 'situation': 2872, 'dancing': 2873, 'chips': 2874, 'walk': 2875, 'gait': 2876, 'lust': 2877, 'perjured': 2878, 'savage': 2879, 'extreme': 2880, 'enjoyed': 2881, 'sooner': 2882, 'hunted': 2883, 'hated': 2884, 'swallowed': 2885, 'bait': 2886, 'taker': 2887, 'mad': 2888, 'pursuit': 2889, 'bliss': 2890, 'proposed': 2891, 'coral': 2892, 'red': 2893, 'snow': 2894, 'breasts': 2895, 'dun': 2896, 'hairs': 2897, 'wires': 2898, 'damasked': 2899, 'reeks': 2900, 'sound': 2901, 'treads': 2902, 'belied': 2903, 'tyrannous': 2904, 'proudly': 2905, 'doting': 2906, 'err': 2907, 'swear': 2908, 'groans': 2909, 'neck': 2910, 'judgments': 2911, 'proceeds': 2912, 'pitying': 2913, 'disdain': 2914, 'ruth': 2915, 'grey': 2916, 'east': 2917, 'ushers': 2918, 'sober': 2919, 'mourning': 2920, 'become': 2921, 'beseem': 2922, 'suit': 2923, 'herself': 2924, 'beshrew': 2925, 'slavery': 2926, 'sweetst': 2927, 'harder': 2928, 'engrossed': 2929, 'forsaken': 2930, 'threefold': 2931, 'crossed': 2932, 'prison': 2933, 'ward': 2934, 'whoeer': 2935, 'rigour': 2936, 'gaol': 2937, 'perforce': 2938, 'confessed': 2939, 'mortgaged': 2940, 'restore': 2941, 'covetous': 2942, 'learned': 2943, 'suretylike': 2944, 'bond': 2945, 'fist': 2946, 'bind': 2947, 'statute': 2948, 'putst': 2949, 'sue': 2950, 'came': 2951, 'debtor': 2952, 'whole': 2953, 'whoever': 2954, 'boot': 2955, 'overplus': 2956, 'spacious': 2957, 'acceptance': 2958, 'addeth': 2959, 'beseechers': 2960, 'admitted': 2961, 'lovesuit': 2962, 'fulfil': 2963, 'receipt': 2964, 'reckoned': 2965, 'untold': 2966, 'corrupt': 2967, 'overpartial': 2968, 'anchored': 2969, 'bay': 2970, 'forged': 2971, 'hooks': 2972, 'tied': 2973, 'several': 2974, 'plot': 2975, 'erred': 2976, 'transferred': 2977, 'swears': 2978, 'untutored': 2979, 'unlearned': 2980, 'subtleties': 2981, 'vainly': 2982, 'simply': 2983, 'credit': 2984, 'falsespeaking': 2985, 'sides': 2986, 'suppressed': 2987, 'unjust': 2988, 'habit': 2989, 'flattered': 2990, 'justify': 2991, 'slay': 2992, 'needst': 2993, 'oerpressed': 2994, 'dart': 2995, 'outright': 2996, 'rid': 2997, 'press': 2998, 'manner': 2999, 'pitywanting': 3000, 'testy': 3001, 'news': 3002, 'physicians': 3003, 'despair': 3004, 'madness': 3005, 'illwresting': 3006, 'slanderers': 3007, 'ears': 3008, 'believed': 3009, 'despise': 3010, 'pleased': 3011, 'dote': 3012, 'cars': 3013, 'tune': 3014, 'delighted': 3015, 'prone': 3016, 'invited': 3017, 'senses': 3018, 'dissuade': 3019, 'foolish': 3020, 'unswayed': 3021, 'likeness': 3022, 'awards': 3023, 'merits': 3024, 'reproving': 3025, 'scarlet': 3026, 'ornaments': 3027, 'sealed': 3028, 'robbed': 3029, 'beds': 3030, 'revenues': 3031, 'rents': 3032, 'woo': 3033, 'importune': 3034, 'deserve': 3035, 'pitied': 3036, 'selfexample': 3037, 'denied': 3038, 'huswife': 3039, 'runs': 3040, 'feathered': 3041, 'broke': 3042, 'dispatch': 3043, 'neglected': 3044, 'chase': 3045, 'busy': 3046, 'follow': 3047, 'prizing': 3048, 'infants': 3049, 'runst': 3050, 'afar': 3051, 'pray': 3052, 'loud': 3053, 'crying': 3054, 'suggest': 3055, 'angel': 3056, 'worser': 3057, 'coloured': 3058, 'female': 3059, 'tempteth': 3060, 'saint': 3061, 'devil': 3062, 'wooing': 3063, 'purity': 3064, 'fiend': 3065, 'directly': 3066, 'doubt': 3067, 'breathed': 3068, 'languished': 3069, 'woeful': 3070, 'mercy': 3071, 'chiding': 3072, 'followed': 3073, 'flown': 3074, 'threw': 3075, 'saved': 3076, 'saying': 3077, 'centre': 3078, 'rebel': 3079, 'powers': 3080, 'array': 3081, 'dearth': 3082, 'costly': 3083, 'inheritors': 3084, 'excess': 3085, 'charge': 3086, 'servants': 3087, 'aggravate': 3088, 'buy': 3089, 'terms': 3090, 'selling': 3091, 'dross': 3092, 'fed': 3093, 'feed': 3094, 'theres': 3095, 'dying': 3096, 'longing': 3097, 'nurseth': 3098, 'disease': 3099, 'preserve': 3100, 'uncertain': 3101, 'sickly': 3102, 'physician': 3103, 'angry': 3104, 'prescriptions': 3105, 'desperate': 3106, 'except': 3107, 'franticmad': 3108, 'unrest': 3109, 'discourse': 3110, 'random': 3111, 'sworn': 3112, 'correspondence': 3113, 'censures': 3114, 'falsely': 3115, 'aright': 3116, 'denote': 3117, 'vexed': 3118, 'watching': 3119, 'marvel': 3120, 'mistake': 3121, 'sees': 3122, 'clears': 3123, 'keepst': 3124, 'wellseeing': 3125, 'partake': 3126, 'alltyrant': 3127, 'hateth': 3128, 'frownst': 3129, 'fawn': 3130, 'lourst': 3131, 'revenge': 3132, 'service': 3133, 'worship': 3134, 'commanded': 3135, 'insufficiency': 3136, 'brightness': 3137, 'refuse': 3138, 'warrantise': 3139, 'exceeds': 3140, 'abhor': 3141, 'unworthiness': 3142, 'raised': 3143, 'conscience': 3144, 'cheater': 3145, 'betraying': 3146, 'nobler': 3147, 'treason': 3148, 'stays': 3149, 'rising': 3150, 'drudge': 3151, 'swearing': 3152, 'act': 3153, 'bedvow': 3154, 'torn': 3155, 'vowing': 3156, 'oaths': 3157, 'breach': 3158, 'twenty': 3159, 'misuse': 3160, 'honest': 3161, 'enlighten': 3162, 'blindness': 3163, 'cupid': 3164, 'asleep': 3165, 'maid': 3166, 'dians': 3167, 'lovekindling': 3168, 'quickly': 3169, 'steep': 3170, 'valleyfountain': 3171, 'endure': 3172, 'seeting': 3173, 'bath': 3174, 'newfired': 3175, 'trial': 3176, 'touch': 3177, 'withal': 3178, 'thither': 3179, 'hied': 3180, 'distempered': 3181, 'lovegod': 3182, 'lying': 3183, 'heartinflaming': 3184, 'nymphs': 3185, 'vowed': 3186, 'chaste': 3187, 'tripping': 3188, 'votary': 3189, 'legions': 3190, 'warmed': 3191, 'sleeping': 3192, 'virgin': 3193, 'disarmed': 3194, 'quenched': 3195, 'cool': 3196, 'discased': 3197, 'thrall': 3198, 'heats': 3199, 'cools': 3200}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifR2i89zpnGD",
        "outputId": "088aba3d-d379-4386-df72-111c118547c8"
      },
      "source": [
        "# now generate a random sonnet with 14 lines and 10 syllables each\r\n",
        "emission = []\r\n",
        "states = []\r\n",
        "L = np.array(hmm8.L)\r\n",
        "D = np.array(hmm8.D)  \r\n",
        "O = np.array(hmm8.O)\r\n",
        "A = np.array(hmm8.A)\r\n",
        "obs_map_r = obs_map_reverser(obs_map)\r\n",
        "\r\n",
        "# make sure we have 14 lines\r\n",
        "line_syls = []\r\n",
        "for i in range(0,14):\r\n",
        "  # each line with 10 syllables\r\n",
        "  emission = []\r\n",
        "  states = []\r\n",
        "  k = 0\r\n",
        "  # Initial state\r\n",
        "  states.append(np.random.randint(0,L))\r\n",
        "  emission.append(np.random.choice(D,None, True, O[states[0],:]))\r\n",
        "  syl_count= syl_dict[obs_map_r[emission[0]]]\r\n",
        "  if len(syl_count)>1:\r\n",
        "    # check to use the one not at the end or just randomly\r\n",
        "    not_end_count = [x for x in syl_count if not x.startswith('E')]\r\n",
        "    syl_count = not_end_count\r\n",
        "    # if syl_count[0][0]!='E':\r\n",
        "    #   syl_count = syl_count[0][0]\r\n",
        "  try:\r\n",
        "    k+=int(syl_count[0])\r\n",
        "  except:\r\n",
        "    import pdb; pdb.set_trace()\r\n",
        "  j=0\r\n",
        "  #print(k)\r\n",
        "  while k<10:\r\n",
        "    #import pdb; pdb.set_trace()\r\n",
        "    j+=1\r\n",
        "    # generate next word\r\n",
        "    states.append(np.random.choice(L,None, True, A[states[j-1],:]))\r\n",
        "    emission.append(np.random.choice(D,None, True, O[states[j],:]))\r\n",
        "    syl_count= syl_dict[obs_map_r[emission[j]]]\r\n",
        "    #print(obs_map_r[emission[j]])\r\n",
        "    if len(syl_count)>1:\r\n",
        "      end_count = [x for x in syl_count if x.startswith('E')]\r\n",
        "      #import pdb; pdb.set_trace()\r\n",
        "      if len(end_count) >= 1:\r\n",
        "        if k + int(end_count[0][-1]) > 10:\r\n",
        "          # if equal to 10 pick this word and save sentence\r\n",
        "          if k + int(end_count[0][-1]) == 10:\r\n",
        "            syl_count=int(end_count[0][-1])\r\n",
        "        # check to use the correct one\r\n",
        "        else:\r\n",
        "          for s in syl_count:\r\n",
        "            if s[0]!='E':\r\n",
        "              syl_count = int(s)\r\n",
        "      else:\r\n",
        "        syl_count = int(syl_count[0])\r\n",
        "    else:\r\n",
        "      syl_count = int(syl_count[0])\r\n",
        "    if k+syl_count>10:\r\n",
        "      # regernerate\r\n",
        "      while k+syl_count>10:\r\n",
        "        states[j] = (np.random.choice(L,None, True, A[states[j-1],:]))\r\n",
        "        emission[j] = (np.random.choice(D,None, True, O[states[j],:]))\r\n",
        "        syl_count= syl_dict[obs_map_r[emission[j]]]\r\n",
        "        end_count = [x for x in syl_count if x.startswith('E')]\r\n",
        "        if len(end_count) >= 1:\r\n",
        "          syl_count=int(end_count[0][-1])\r\n",
        "        else:\r\n",
        "          syl_count = int(syl_count[0])\r\n",
        "    try:\r\n",
        "      k+=syl_count # or just pick the first one\r\n",
        "    except:\r\n",
        "      import pdb; pdb.set_trace()\r\n",
        "    #print(k)\r\n",
        "    if k>=10:\r\n",
        "      line_syls.append(k)\r\n",
        "  sentence = [obs_map_r[i] for i in emission]\r\n",
        "  print(' '.join(sentence).capitalize())\r\n",
        "  # break the line after 4/8/12 lines\r\n",
        "  if (i == 3 or i == 7 or i == 11):\r\n",
        "    print('\\n')\r\n",
        "print(line_syls)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Strumpeted disgrace and it might thou foul\n",
            "Expired prey suffer tired which time but should\n",
            "Walks issueless their false of of conquest\n",
            "Of of wards to should to toil outward that\n",
            "\n",
            "\n",
            "Mine being it blest seem quick threescore and say\n",
            "Thy angel prove to were out false hath not\n",
            "Who betraying rotten being the fair and\n",
            "Deep not triumph of my praise day my some\n",
            "\n",
            "\n",
            "Who amis some lives my but could by did\n",
            "Selfexample hath think it affections\n",
            "Eye did are shore by filching beauty sin\n",
            "Thee on what brief active made but not then\n",
            "\n",
            "\n",
            "Virtue commence and richer of thy thou\n",
            "Winter and but that their till doth for but\n",
            "[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rllt1ZYsj1NN"
      },
      "source": [
        "# Rhyming HMM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJOUjMMojWS1"
      },
      "source": [
        "Loading the rhyming dictionary made using the example rhymes in the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqNDclgFY78W"
      },
      "source": [
        "# Loading from our github\r\n",
        "rhyme_array_raw = np.genfromtxt('https://raw.githubusercontent.com/treyra/CS155_miniproject3/main/data/rhyme_list.txt',delimiter='\\t',dtype=None,encoding='ISO-8859-1')\r\n",
        "\r\n",
        "rhyme_array = np.zeros((len(rhyme_array_raw),2),dtype=object)\r\n",
        "for i,rhymes in enumerate(rhyme_array_raw):\r\n",
        "    #Stored as a np array written to a text file, so remove the brackets\r\n",
        "    rhyme_array[i,0] = rhymes.split()[0][2:-1]\r\n",
        "    rhyme_array[i,1] = rhymes.split()[1][1:-2]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6mw4Zd0m9Er"
      },
      "source": [
        "class RhymingHiddenMarkovModel ( HiddenMarkovModel ):\r\n",
        "    '''\r\n",
        "    Class implementation of Hidden Markov Models for rhyming sonnets\r\n",
        "    '''\r\n",
        "\r\n",
        "    def __init__(self, A, O,rhyme_array,syl_dict,obs_map):\r\n",
        "        \r\n",
        "        self.rhyme_array = rhyme_array\r\n",
        "        self.syl_dict = syl_dict\r\n",
        "        self.obs_map = obs_map\r\n",
        "        self.obs_map_r = obs_map_reverser(obs_map)\r\n",
        "        HiddenMarkovModel.__init__(self,A,O)\r\n",
        "\r\n",
        "    def emit_line(self, numSyls = 10, endSeed=None):\r\n",
        "        \"\"\"\r\n",
        "        Generate a random line backwards to forwards\r\n",
        "        using a seeded ending word, if provided\r\n",
        "        Parameters\r\n",
        "        ----------\r\n",
        "        numSyls : int\r\n",
        "            Number of syllables the line should have. \r\n",
        "            Default is 10\r\n",
        "        endSeed : tuple (int,string)\r\n",
        "            The HMM state and the string the line will\r\n",
        "            end in, if any.\r\n",
        "        \"\"\"\r\n",
        "        #Line to emit\r\n",
        "        line = None \r\n",
        "\r\n",
        "        #No seed, pick random initial state\r\n",
        "        if endSeed is None:\r\n",
        "            state = np.random.randint(0,self.L)\r\n",
        "            line = np.array([np.random.choice(self.D,p=self.O[state,:])])\r\n",
        "        else:\r\n",
        "            state = endSeed[0]\r\n",
        "            line = np.array([self.obs_map[endSeed[1]]])\r\n",
        "        k = 0\r\n",
        "        # Initial state\r\n",
        "        syl_count= syl_dict[self.obs_map_r[line[0]]]\r\n",
        "        if len(syl_count)>1:\r\n",
        "          # check to use the one not at the end or just randomly\r\n",
        "          not_end_count = [x for x in syl_count if not x.startswith('E')]\r\n",
        "          syl_count = not_end_count\r\n",
        "          # if syl_count[0][0]!='E':\r\n",
        "          #   syl_count = syl_count[0][0]\r\n",
        "        try:\r\n",
        "          k+=int(syl_count[0])\r\n",
        "        except:\r\n",
        "          import pdb; pdb.set_trace()\r\n",
        "        #Now loop backwards and generate rest of line before word\r\n",
        "        j = 0\r\n",
        "        prevState = state\r\n",
        "        while k < 10:\r\n",
        "            j+=1\r\n",
        "            # generate next word (NOTE: we flipped the A matrix because we want to know the \r\n",
        "            #probability of transitioning TO the previous state)\r\n",
        "            state = np.random.choice(self.L,p= self.A[:,prevState]/np.linalg.norm(self.A[:,prevState],1))\r\n",
        "            line = np.concatenate(([np.random.choice(self.D,p=self.O[state,:])],line)) \r\n",
        "            syl_count= syl_dict[self.obs_map_r[line[0]]]\r\n",
        "            #print(obs_map_r[line[0]])\r\n",
        "            if len(syl_count)>1:\r\n",
        "              end_count = [x for x in syl_count if x.startswith('E')]\r\n",
        "              if len(end_count) >= 1:\r\n",
        "                if k + int(end_count[0][-1]) > 10:\r\n",
        "                  # if equal to 10 pick this word and save sentence\r\n",
        "                  if k + int(end_count[0][-1]) == 10:\r\n",
        "                    syl_count=int(end_count[0][-1])\r\n",
        "                # check to use the correct one\r\n",
        "                else:\r\n",
        "                  for s in syl_count:\r\n",
        "                    if s[0]!='E':\r\n",
        "                      syl_count = int(s)\r\n",
        "              else:\r\n",
        "                syl_count = int(syl_count[0])\r\n",
        "            else:\r\n",
        "              syl_count = int(syl_count[0])\r\n",
        "            if k+syl_count>10:\r\n",
        "              # regernerate\r\n",
        "              while k+syl_count>10:\r\n",
        "                state = np.random.choice(self.L,p= self.A[:,prevState]/np.linalg.norm(self.A[:,prevState],1))\r\n",
        "                line[0] = (np.random.choice(self.D,p = self.O[state,:]))\r\n",
        "                syl_count= syl_dict[self.obs_map_r[line[0]]]\r\n",
        "                end_count = [x for x in syl_count if x.startswith('E')]\r\n",
        "                if len(end_count) >= 1:\r\n",
        "                  syl_count=int(end_count[0][-1])\r\n",
        "                else:\r\n",
        "                  syl_count = int(syl_count[0])\r\n",
        "            try:\r\n",
        "              k+=syl_count # or just pick the first one\r\n",
        "            except:\r\n",
        "              import pdb; pdb.set_trace()\r\n",
        "            #print(k)\r\n",
        "            if k>=10:\r\n",
        "              return [self.obs_map_r[i] for i in line]\r\n",
        "    def genRhymingSonnet(self):\r\n",
        "        \"\"\"\r\n",
        "        Uses rhyme dict to seed lines for a rhyming sonnet\r\n",
        "        \"\"\"\r\n",
        "        sonnet = np.array([[]],dtype=object)\r\n",
        "        #Generate 14 rhyming lines\r\n",
        "        #List of indicies already picked and the word in the pair used\r\n",
        "        #(set to -1 initially)\r\n",
        "        used = np.zeros((7,2)) - 1\r\n",
        "\r\n",
        "        for i in range(14):\r\n",
        "            #Let the first word in the rhyme pair be in any order\r\n",
        "            firstWord = -1\r\n",
        "            if i == 0 or i == 1 or i == 4 or i == 5 or i == 8 or i == 9 or i == 12:\r\n",
        "                rhyme = np.random.randint(0,len(self.rhyme_array))\r\n",
        "                #Redraw for uniqueness (desired behavior?)\r\n",
        "                while rhyme in used:\r\n",
        "                    rhyme = np.random.randint(0,len(self.rhyme_array))\r\n",
        "                #Using integer math to get the right index for each pair of rhymes\r\n",
        "                used[int((i+1)/2),0] = rhyme\r\n",
        "                #Randomly draw the last word, save so we use other next time\r\n",
        "                lastWord = np.random.randint(0,len(self.rhyme_array[rhyme]))\r\n",
        "                used[int((i+1)/2),1] = lastWord\r\n",
        "            else:\r\n",
        "                #Using integer math to get the right index for each pair of rhymes\r\n",
        "                rhyme = int(used[int((i-1)/2),0])\r\n",
        "                #Get the other word in pair (this is to allow for N lenght lists of rhymes)\r\n",
        "                lastWord = np.random.randint(0,len(self.rhyme_array[rhyme])-1)\r\n",
        "                #If we got the word we already used, just assign the one we excluded from the draw\r\n",
        "                if lastWord == used[int((i-1)/2),1]:\r\n",
        "                    lastWord = len(self.rhyme_array[rhyme])-1\r\n",
        "                lastWord = int(lastWord)\r\n",
        "            line = self.emit_line(endSeed=(np.random.randint(0,self.L),self.rhyme_array[rhyme,lastWord]))\r\n",
        "            print(i,end = \": \")\r\n",
        "            print(' '.join(line).capitalize())\r\n",
        "            sonnet = np.append(sonnet,line)           \r\n",
        "        return sonnet\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160,
          "referenced_widgets": [
            "0af71856de45444286d7f4abf62bbbdc",
            "17f917189f64471b9b876b7703142452",
            "ef08d0e2295e4f69bf950621bb6cf0b5",
            "6d63467299ad424b8032ec6386d5330f",
            "00f1ab8fa48b4d55b98b78d87dcd3d47",
            "f316cc55894947c5ba23b3d04c324630",
            "a01589e4ff024af193010f219ef1d9b0",
            "845cffdb33e84731acb84fbc8863ac4e"
          ]
        },
        "id": "gsZ-FvhJweUv",
        "outputId": "107fa20a-5ee2-46c2-d700-a705139b2d61"
      },
      "source": [
        "# train a HMM (only a few epochs)\r\n",
        "betterHMM = unsupervised_HMM(obs, 20, 50)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0af71856de45444286d7f4abf62bbbdc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 10\n",
            "Iteration: 20\n",
            "Iteration: 30\n",
            "Iteration: 40\n",
            "Iteration: 50\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zs3fjGUk7Aoa",
        "outputId": "2cfd76aa-843a-4989-ecc1-0b72a0012962"
      },
      "source": [
        "# mount drive\r\n",
        "# save data by line and data by sonnet\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('./drive',force_remount=True)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at ./drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBz1etao7F7Q"
      },
      "source": [
        "np.save('/content/drive/My Drive/CS155_miniproject_3/20_50_A.npy', betterHMM.A)    \r\n",
        "np.save('/content/drive/My Drive/CS155_miniproject_3/20_50_O.npy', betterHMM.O)    "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbuVyRJyuNch",
        "outputId": "189a1f05-69e4-44df-92c1-4d0e2176a6fa"
      },
      "source": [
        "#Gen the rhyming Sonnet\r\n",
        "rhyme_hmm = RhymingHiddenMarkovModel(hmm8.A, hmm8.O,rhyme_array,syl_dict,obs_map)\r\n",
        "sonnet = rhyme_hmm.genRhymingSonnet()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: Desire of the shadow in cheeks a are\n",
            "1: Five one lack she thy yore moods self love stand\n",
            "2: Which and my up hand of yet let sun care\n",
            "3: Thee marriage if lies this grows this said land\n",
            "4: Than my to mortal hath friends since to need\n",
            "5: That on and none my her making your hope\n",
            "6: Limbs knew name store active anchored exceed\n",
            "7: Times twofold back prime cures the at the scope\n",
            "8: Keeps taught lovst like my another thy white\n",
            "9: She may favour hate day and name alone\n",
            "10: Thee darling though o depends a delight\n",
            "11: Change or epitaph see eves leave truth prone\n",
            "12: Thing is wit second methinks receivest\n",
            "13: Pleasing is be not thou i deceivest\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKD9XQCtDayr",
        "outputId": "c8a34723-0d7a-4b4e-f543-e2641c23eeca"
      },
      "source": [
        "#Gen the rhyming Sonnet\r\n",
        "rhyme_hmm = RhymingHiddenMarkovModel(betterHMM.A, betterHMM.O,rhyme_array,syl_dict,obs_map)\r\n",
        "sonnet = rhyme_hmm.genRhymingSonnet()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: Policy whilst every being poor feeding\n",
            "1: Or i daily is i my wantonly\n",
            "2: Self by persuade your hours which right needing\n",
            "3: Woe hems shame mayst find can beauty love dye\n",
            "4: Even watching waste heart time pity for pride\n",
            "5: And and in till boast i in proceeds ill\n",
            "6: One bids answers why kingdom she break ride\n",
            "7: In in thou be thou filching in in skill\n",
            "8: Hours time might if may any might left wronk\n",
            "9: By in thou in suit thou mercy and moan\n",
            "10: And were out what man i my my nights tongue\n",
            "11: Last this his still think the love this the gone\n",
            "12: Live worth she woe and griefs your tell disgrace\n",
            "13: For thou grace a five your thy beautys face\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160,
          "referenced_widgets": [
            "df1bc8c1b4004c31ac0a730b4ccae65d",
            "58a23c06292a46d285823237bc20b8ed",
            "bdbf4229b8a54d2aa087c3bf10f13fe9",
            "da0030480bf2444981d9cf2d2f6434b0",
            "0854589d6bc947c193a8766ec5144f49",
            "910cbd561b194e3285bba4e89eee098f",
            "d73bc972fc9a4c35aa154fff259f266d",
            "f8333e5d0f2e42c5a19bc1f8ec10786f"
          ]
        },
        "id": "A165id94ye4n",
        "outputId": "7441ccce-c090-4d4f-bf9a-954036b53dfc"
      },
      "source": [
        "# train a HMM (only a few epochs)\r\n",
        "betterHMM = unsupervised_HMM(obs, 15, 50)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df1bc8c1b4004c31ac0a730b4ccae65d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 10\n",
            "Iteration: 20\n",
            "Iteration: 30\n",
            "Iteration: 40\n",
            "Iteration: 50\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AzUZUdREOPz"
      },
      "source": [
        "np.save('/content/drive/My Drive/CS155_miniproject_3/15_50_A.npy', betterHMM.A)    \r\n",
        "np.save('/content/drive/My Drive/CS155_miniproject_3/15_50_O.npy', betterHMM.O)    "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160,
          "referenced_widgets": [
            "35f371baad5b4a61a033ea6a52078efb",
            "1ec40b9de2e74a9f9d43cb3c3bbe383e",
            "7cf05b769e1542baa5ea7179cb27b1ad",
            "ec50b492c0c24bfab693efff8ad7ab18",
            "624279bda8a64511a1e335230521d6fc",
            "0c6c251369c74125867efa75ab79768e",
            "4198e6897cbf45baa2a1a8c4d15dff85",
            "04de8865e6ae4d61934256c7a85712a0"
          ]
        },
        "id": "GLjf-piTERDb",
        "outputId": "4982ddaa-5cad-4d59-f79b-7c11bc86e82b"
      },
      "source": [
        "# train a HMM (only a few epochs)\r\n",
        "betterHMM = unsupervised_HMM(obs, 10, 50)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35f371baad5b4a61a033ea6a52078efb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 10\n",
            "Iteration: 20\n",
            "Iteration: 30\n",
            "Iteration: 40\n",
            "Iteration: 50\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmsRdlLQERYj"
      },
      "source": [
        "np.save('/content/drive/My Drive/CS155_miniproject_3/10_50_A.npy', betterHMM.A)    \r\n",
        "np.save('/content/drive/My Drive/CS155_miniproject_3/10_50_O.npy', betterHMM.O)    "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160,
          "referenced_widgets": [
            "48233a5cdab9415ea9c6d82efa5b466c",
            "6531af6dd72146f7a20f4828d59a6a68",
            "518f0207927f48198fb8b85666641846",
            "341ad478e2664620b4c2653e6d46fcf2",
            "1b34676f08ee419eaed42be2d16cd3ef",
            "2433be9fa2d14a0fb47c266cd308f3c6",
            "ceb316dd152c4f4597953d4fb8b32d67",
            "e6dd8acf627145c4a85553c582ea5a6b"
          ]
        },
        "id": "3QzvsYn4FBWT",
        "outputId": "9cb1016e-32c8-45bc-9832-115ffc4d3dd2"
      },
      "source": [
        "# train a HMM (only a few epochs)\r\n",
        "hmm5 = unsupervised_HMM(obs, 5, 50)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48233a5cdab9415ea9c6d82efa5b466c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 10\n",
            "Iteration: 20\n",
            "Iteration: 30\n",
            "Iteration: 40\n",
            "Iteration: 50\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Aqv-wGQFFAL"
      },
      "source": [
        "np.save('/content/drive/My Drive/CS155_miniproject_3/5_50_A.npy', hmm5.A)    \r\n",
        "np.save('/content/drive/My Drive/CS155_miniproject_3/5_50_O.npy', hmm5.O)    "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWX7jAEZUX5f",
        "outputId": "8488a315-79e8-45ef-da90-183094a9558f"
      },
      "source": [
        "#Gen the rhyming Sonnet\r\n",
        "rhyme_hmm = RhymingHiddenMarkovModel(betterHMM.A, betterHMM.O,rhyme_array,syl_dict,obs_map)\r\n",
        "sonnet = rhyme_hmm.genRhymingSonnet()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: Tongue beauties lays out proud my lips taken\n",
            "1: Leads thou how true birds cease back assured\n",
            "2: Inward the a for pale sweet keep shaken\n",
            "3: Now that all thine hath hath if and endured\n",
            "4: Tan thee i that why fire is that for stage\n",
            "5: I must form i despite those do then verse\n",
            "6: Dulness forgive friend fortune absence rage\n",
            "7: Is many the from i desire birds rehearse\n",
            "8: True thy suns but i victor doth behind\n",
            "9: Mistress in they then even of believe style\n",
            "10: Worlds finds sweet gravity these how since kind\n",
            "11: My consumst my rigour form kind compile\n",
            "12: Height the is a a seeming house my know\n",
            "13: Needs then so state edge which i gain eyes show\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVV70ggOUcVY",
        "outputId": "bcffd2c9-e82a-40f1-de31-129cfe58b4ee"
      },
      "source": [
        "#Gen the rhyming Sonnet\r\n",
        "rhyme_hmm = RhymingHiddenMarkovModel(hmm5.A, hmm5.O,rhyme_array,syl_dict,obs_map)\r\n",
        "sonnet = rhyme_hmm.genRhymingSonnet()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: Whom from invention some poor with a thee\n",
            "1: Who say where and and which not largess love\n",
            "2: Which be for i red and i pleasure me\n",
            "3: Rare touches from wet is on my in prove\n",
            "4: That confounds happy as looks for i thine\n",
            "5: Through mind love fears fortune speak ordering\n",
            "6: Should and alone have but enough to mine\n",
            "7: My his on at preposterously in sing\n",
            "8: And and folly hate untutored it edge\n",
            "9: Poor sum long high remembered high as dyed\n",
            "10: Red you being would as although privilege\n",
            "11: To a is wombs his all to dignified\n",
            "12: Who his the sins loves thy my not swearing\n",
            "13: Swear haste but beauty rich ever bearing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eU1x-zFP3uT",
        "outputId": "174284aa-37a7-4a08-b1f0-9974be73d21a"
      },
      "source": [
        "import requests\r\n",
        "import io\r\n",
        "\r\n",
        "response = requests.get('https://github.com/treyra/CS155_miniproject3/blob/main/trained_hmms/5_50_A.npy?raw=true')\r\n",
        "response.raise_for_status()\r\n",
        "loadA = np.load(io.BytesIO(response.content))  \r\n",
        "response = requests.get('https://github.com/treyra/CS155_miniproject3/blob/main/trained_hmms/5_50_O.npy?raw=true')\r\n",
        "response.raise_for_status()\r\n",
        "loadO = np.load(io.BytesIO(response.content)) \r\n",
        "rhyme_hmm = RhymingHiddenMarkovModel(loadA, loadO,rhyme_array,syl_dict,obs_map)\r\n",
        "sonnet = rhyme_hmm.genRhymingSonnet()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: Your doth i the mens no cold my new store\n",
            "1: Which of ten remembered love brow all woe\n",
            "2: Write doth plight therefore esteeming i yore\n",
            "3: Thou on excuse his in with thou from so\n",
            "4: Do it from foul mend have may and thee part\n",
            "5: The furrows and your thee busy feed weed\n",
            "6: Pine is each is love whit what to to heart\n",
            "7: Lovers thou eye am muse for he proceed\n",
            "8: Thrusts of when lesson and give crushed account\n",
            "9: State me of this themselves love stops behind\n",
            "10: Or self the thy mens i thy i surmount\n",
            "11: Own delight still thou sooner you thy kind\n",
            "12: If how and statues that to be lies new\n",
            "13: In not thou heart for effect him find view\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6q88sorZPBn"
      },
      "source": [
        "#RNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC0bSyR3ZQGG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}